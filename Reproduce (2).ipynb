{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:27.683819Z",
          "start_time": "2025-01-19T18:47:24.461982Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "347d8ee9",
      "metadata": {
        "id": "347d8ee9"
      },
      "outputs": [],
      "source": [
        "def normalize_adjacency_dense_gpu(A):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    A = A.to(device)  # Move to GPU if available\n",
        "\n",
        "    # Ensure self-loops\n",
        "    A = A + torch.eye(A.size(0), device=A.device)\n",
        "\n",
        "    # Degree vector\n",
        "    row_sum = torch.sum(A, dim=1)\n",
        "\n",
        "    # Avoid division by zero by adding a small epsilon\n",
        "    D_inv_sqrt = torch.diag(1.0 / torch.sqrt(1e-10+ row_sum ))\n",
        "    # Normalize adjacency\n",
        "    normalized_A = D_inv_sqrt @ A @ D_inv_sqrt\n",
        "\n",
        "    # Enforce symmetry (optional but helps to handle numerical instability)\n",
        "    normalized_A = (normalized_A + normalized_A.T) / 2.0\n",
        "\n",
        "    return normalized_A\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd15f164b0648153",
      "metadata": {
        "collapsed": false,
        "id": "bd15f164b0648153"
      },
      "source": [
        "Define the GCN Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "id": "f7674ef8ed978f90",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:28.346875Z",
          "start_time": "2025-01-19T18:47:28.339402Z"
        },
        "id": "f7674ef8ed978f90"
      },
      "outputs": [],
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
        "        #self.weight = nn.Parameter(torch.randn(output_dim, input_dim))  # output_dim should be first\n",
        "\n",
        "\n",
        "    def forward(self, X, A_tilde):\n",
        "        return A_tilde @ X @ self.weight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49006fa248be27a7",
      "metadata": {
        "collapsed": false,
        "id": "49006fa248be27a7"
      },
      "source": [
        "Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "c09f77a93ea6ad03",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:32.193578Z",
          "start_time": "2025-01-19T18:47:32.188017Z"
        },
        "id": "c09f77a93ea6ad03"
      },
      "outputs": [],
      "source": [
        "class InferenceModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(InferenceModel, self).__init__()\n",
        "        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n",
        "        self.gcn2_mu = GCNLayer(hidden_dim, latent_dim)\n",
        "        self.gcn2_logsigma = GCNLayer(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, X, A_tilde):\n",
        "        A_tilde = A_tilde / (A_tilde.sum(dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "        H = F.relu(self.gcn1(X, A_tilde))  # Shared first layer\n",
        "        if torch.isnan(H).any():\n",
        "            print(\"NaN detected in H!\")\n",
        "\n",
        "        mu = self.gcn2_mu(H, A_tilde)  # Mean matrix\n",
        "        log_sigma = self.gcn2_logsigma(H, A_tilde)  # Log-variance matrix\n",
        "        return mu, log_sigma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef56856a0b72bb45",
      "metadata": {
        "collapsed": false,
        "id": "ef56856a0b72bb45"
      },
      "source": [
        "Variational Grpah Auto-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "ff3b3bbf607e4457",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:33.185231Z",
          "start_time": "2025-01-19T18:47:33.179795Z"
        },
        "id": "ff3b3bbf607e4457"
      },
      "outputs": [],
      "source": [
        "class VGAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VGAE, self).__init__()\n",
        "        self.encoder = InferenceModel(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, X, A_tilde):\n",
        "        mu, log_sigma = self.encoder(X, A_tilde)\n",
        "        # Reparameterization trick\n",
        "        std = torch.exp(0.5 * log_sigma)\n",
        "        std = torch.clamp(std, min=1e-5, max=10)\n",
        "        eps = torch.randn_like(std)\n",
        "        if torch.isnan(std).any():\n",
        "            print(\"NaN detected in std!\")\n",
        "        Z = mu + eps * std\n",
        "        Z = F.normalize(Z, p=2, dim=1)  # Normalize rows of Z to unit length\n",
        "        #Z = Z / torch.sqrt(torch.tensor(Z.shape[1], dtype=torch.float32, device=Z.device))\n",
        "        if torch.isnan(mu).any():\n",
        "            print(\"NaN detected in mu!\")\n",
        "\n",
        "        if torch.isnan(log_sigma).any():\n",
        "            print(\"NaN detected in log_sigma!\")\n",
        "\n",
        "        A_reconstructed = torch.sigmoid(torch.matmul(Z, Z.T))\n",
        "        return Z, A_reconstructed, mu, log_sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "8907c838",
      "metadata": {
        "id": "8907c838"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VGAE_MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = InferenceModel(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "        # MLP Decoder (2-layer perceptron)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2 * latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 4, 1)\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, X, A_tilde, edge_index=None):\n",
        "        mu, log_sigma = self.encoder(X, A_tilde)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        std = torch.exp(0.5 * log_sigma)\n",
        "        std = torch.clamp(std, max=1e5)\n",
        "        eps = torch.randn_like(std)\n",
        "        Z = mu + eps * std\n",
        "        #Z = F.normalize(Z, p=2, dim=1)  # Normalize rows of Z to unit length\n",
        "\n",
        "\n",
        "\n",
        "        batch_size = 10000  # Adjust based on memory\n",
        "        num_edges = edge_index.shape[1]\n",
        "        A_reconstructed_list = []\n",
        "\n",
        "        for i in range(0, num_edges, batch_size):\n",
        "            batch_edges = edge_index[:, i : i + batch_size]\n",
        "            src, dst = batch_edges\n",
        "            Z_concat = torch.cat([Z[src], Z[dst]], dim=1)\n",
        "            A_reconstructed_list.append(torch.sigmoid(self.decoder(Z_concat)).squeeze())\n",
        "\n",
        "        A_reconstructed = torch.cat(A_reconstructed_list)\n",
        "\n",
        "        return Z, A_reconstructed, mu, log_sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "9ad315de",
      "metadata": {
        "id": "9ad315de"
      },
      "outputs": [],
      "source": [
        "class WeightedInnerProductDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(latent_dim))  # Learnable weight vector\n",
        "\n",
        "    def forward(self, Z):\n",
        "        Z_weighted = Z * self.weight  # Apply element-wise weight\n",
        "        A_reconstructed = torch.sigmoid(torch.matmul(Z, Z_weighted.T))  # Full adjacency matrix\n",
        "        return A_reconstructed\n",
        "\n",
        "\n",
        "class VGAE_W(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = InferenceModel(input_dim, hidden_dim, latent_dim)\n",
        "        self.decoder = WeightedInnerProductDecoder(latent_dim)\n",
        "\n",
        "    def forward(self, X, A_tilde):\n",
        "        mu, log_sigma = self.encoder(X, A_tilde)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        std = torch.exp(0.5 * log_sigma)\n",
        "        std = torch.clamp(std, max=1e5)\n",
        "        eps = torch.randn_like(std)\n",
        "        Z = mu + eps * std\n",
        "        Z = F.normalize(Z, p=2, dim=1)  # Normalize rows of Z to unit length\n",
        "\n",
        "        A_reconstructed = self.decoder(Z)  # No need for edge_index now\n",
        "\n",
        "        return Z, A_reconstructed, mu, log_sigma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ab8fce30d3c266",
      "metadata": {
        "collapsed": false,
        "id": "14ab8fce30d3c266"
      },
      "source": [
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "bb389713323ee3d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:34.115960Z",
          "start_time": "2025-01-19T18:47:34.109603Z"
        },
        "id": "bb389713323ee3d1"
      },
      "outputs": [],
      "source": [
        "def loss_function(A, A_reconstructed, mu, log_sigma):\n",
        "    # Reconstruction loss (Binary Cross-Entropy)\n",
        "    epsilon = 1e-7\n",
        "    A_reconstructed = torch.clamp(A_reconstructed, min=epsilon, max=1 - epsilon)\n",
        "    recon_loss = F.binary_cross_entropy(A_reconstructed, A, reduction='sum')\n",
        "\n",
        "    # KL Divergence\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_sigma.clamp(min=-2, max=2) - mu.clamp(min=-2, max=2).pow(2) - log_sigma.clamp(min=-2, max=2).exp())\n",
        "    #print(log_sigma)\n",
        "    return recon_loss + kl_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "id": "4040da93",
      "metadata": {
        "id": "4040da93"
      },
      "outputs": [],
      "source": [
        "def loss_function_mlp(A, A_reconstructed, mu, log_sigma, edge_index):\n",
        "    src, dst = edge_index  # Edge indices\n",
        "\n",
        "    # If A_reconstructed is 1D, select indices correctly\n",
        "    A_pred = A_reconstructed[torch.arange(edge_index.shape[1])]\n",
        "\n",
        "    # Get true adjacency values\n",
        "    A_true = A[src, dst]\n",
        "\n",
        "    # BCE loss\n",
        "    recon_loss = F.binary_cross_entropy(A_pred, A_true, reduction='sum')\n",
        "\n",
        "    # KL Divergence\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_sigma - mu.pow(2) - log_sigma.clamp(max=10).exp())\n",
        "\n",
        "    return recon_loss + kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dense_adj_custom(edge_index, batch=None, num_nodes=None):\n",
        "\n",
        "    if num_nodes is None:\n",
        "        num_nodes = edge_index.max().item() + 1  # Infer number of nodes if not provided\n",
        "\n",
        "    if batch is None:\n",
        "        adj = torch.zeros((1, num_nodes, num_nodes), dtype=torch.float32, device=edge_index.device)\n",
        "        adj[0, edge_index[0], edge_index[1]] = 1\n",
        "        return adj\n",
        "    else:\n",
        "        num_graphs = batch.max().item() + 1\n",
        "        max_nodes = torch.bincount(batch).max().item()  # Max nodes per graph\n",
        "        adj = torch.zeros((num_graphs, max_nodes, max_nodes), dtype=torch.float32, device=edge_index.device)\n",
        "\n",
        "        for i in range(num_graphs):\n",
        "            mask = batch[edge_index[0]] == i\n",
        "            nodes = batch == i\n",
        "            node_idx = torch.arange(nodes.sum(), device=edge_index.device)\n",
        "            node_map = torch.full((batch.size(0),), -1, device=edge_index.device)\n",
        "            node_map[nodes] = node_idx\n",
        "            adj[i, node_map[edge_index[0, mask]], node_map[edge_index[1, mask]]] = 1\n",
        "\n",
        "        return adj"
      ],
      "metadata": {
        "id": "O5kWR21pLAHp"
      },
      "id": "O5kWR21pLAHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bd79b6477dd33912",
      "metadata": {
        "collapsed": false,
        "id": "bd79b6477dd33912"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae948bb",
      "metadata": {
        "id": "7ae948bb"
      },
      "source": [
        "## VGAE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a7195b60518a90",
      "metadata": {
        "collapsed": false,
        "id": "45a7195b60518a90"
      },
      "source": [
        "### Cora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "id": "c11fa520fbc66c95",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:41.575185Z",
          "start_time": "2025-01-19T18:47:36.971270Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11fa520fbc66c95",
        "outputId": "d993670f-ffcd-466f-d994-c00d3c52997d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CoraFull():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 8710\n",
            "Number of classes: 70\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import CoraFull\n",
        "\n",
        "cora_dataset = CoraFull(root='GraphDatasets/Cora')\n",
        "print(f'Dataset: {cora_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(cora_dataset)}')\n",
        "print(f'Number of features: {cora_dataset.num_features}')\n",
        "print(f'Number of classes: {cora_dataset.num_classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "id": "5c7c260c39e1acd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-19T18:47:42.529637Z",
          "start_time": "2025-01-19T18:47:42.048523Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7c260c39e1acd",
        "outputId": "f8363225-57bb-4583-ef39-8610bcf3116b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency matrix (A): tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
            "Node feature matrix (X): tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Graph data\n",
        "data = cora_dataset[0]\n",
        "X = data.x  # features matrix (N x D)\n",
        "edge_index = data.edge_index  # Edge list (2 x E)\n",
        "\n",
        "# Create the adjacency matrix (A)\n",
        "num_nodes = X.size(0)\n",
        "A = torch.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Convert the edge_index to an adjacency matrix\n",
        "row, col = edge_index\n",
        "A[row, col] = 1\n",
        "A[col, row] = 1  # Since the graph is undirected\n",
        "\n",
        "# Optionally, add self-loops (diagonal elements set to 1)\n",
        "A.fill_diagonal_(1)\n",
        "\n",
        "print(\"Adjacency matrix (A):\", A)\n",
        "print(\"Node feature matrix (X):\", X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4aJGty6BTYF",
        "outputId": "2f1c7043-604b-4b80-e757-84ca04c36122"
      },
      "id": "y4aJGty6BTYF",
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19793, 8710])"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEOdlvn-E764",
        "outputId": "80e1210a-a6cd-42a9-e7d5-dfc2a067bf65"
      },
      "id": "cEOdlvn-E764",
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 126842])"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "cite_dataset = Planetoid(root='GraphDatasets/CiteSeer', name='CiteSeer')\n",
        "print(f'Dataset: {cite_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(cite_dataset)}')\n",
        "print(f'Number of features: {cite_dataset.num_features}')\n",
        "print(f'Number of classes: {cite_dataset.num_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFoSSHMpkcvd",
        "outputId": "0bfb4856-7ab9-4bf5-da45-7e97858484c9"
      },
      "id": "kFoSSHMpkcvd",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 3703\n",
            "Number of classes: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph data\n",
        "data = cite_dataset[0]\n",
        "X = data.x  # features matrix (N x D)\n",
        "edge_index = data.edge_index  # Edge list (2 x E)\n",
        "\n",
        "# Create the adjacency matrix (A)\n",
        "num_nodes = X.size(0)\n",
        "A = torch.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Convert the edge_index to an adjacency matrix\n",
        "row, col = edge_index\n",
        "A[row, col] = 1\n",
        "A[col, row] = 1  # Since the graph is undirected\n",
        "\n",
        "# Optionally, add self-loops (diagonal elements set to 1)\n",
        "A.fill_diagonal_(1)\n",
        "\n",
        "print(\"Adjacency matrix (A):\", A)\n",
        "print(\"Node feature matrix (X):\", X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqDXlYJyke-F",
        "outputId": "c4c2c28e-29c0-4e2f-a6c5-80261dc41fb5"
      },
      "id": "ZqDXlYJyke-F",
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency matrix (A): tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
            "Node feature matrix (X): tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "pub_dataset = Planetoid(root='GraphDatasets/PubMed', name='PubMed')\n",
        "print(f'Dataset: {pub_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(pub_dataset)}')\n",
        "print(f'Number of features: {pub_dataset.num_features}')\n",
        "print(f'Number of classes: {pub_dataset.num_classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMLxfSkVgQWx",
        "outputId": "20692950-2815-4a8e-8951-0cdb4e02f384"
      },
      "id": "mMLxfSkVgQWx",
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: PubMed():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 500\n",
            "Number of classes: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph data\n",
        "data = pub_dataset[0]\n",
        "X = data.x  # features matrix (N x D)\n",
        "edge_index = data.edge_index  # Edge list (2 x E)\n",
        "\n",
        "# Create the adjacency matrix (A)\n",
        "num_nodes = X.size(0)\n",
        "A = torch.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Convert the edge_index to an adjacency matrix\n",
        "row, col = edge_index\n",
        "A[row, col] = 1\n",
        "A[col, row] = 1  # Since the graph is undirected\n",
        "\n",
        "# Optionally, add self-loops (diagonal elements set to 1)\n",
        "A.fill_diagonal_(1)\n",
        "\n",
        "print(\"Adjacency matrix (A):\", A)\n",
        "print(\"Node feature matrix (X):\", X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wkTW6bX4MbT",
        "outputId": "7f4a6301-69a6-4443-e8a8-2c88267376aa"
      },
      "id": "2wkTW6bX4MbT",
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency matrix (A): tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
            "Node feature matrix (X): tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.1046, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0194, 0.0080,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.1078, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0266, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "id": "42133397845d82d2",
      "metadata": {
        "id": "42133397845d82d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def remove_edges_and_sample_optimized(edge_index, num_nodes, test_size=0.1, val_size=0.05):\n",
        "\n",
        "    # Convert edge_index to a set of edges for faster lookup\n",
        "    edges = set(map(tuple, edge_index.t().tolist()))\n",
        "\n",
        "    # Generate all possible node pairs (i, j) for non-edges\n",
        "    all_pairs = set(combinations(range(num_nodes), 2))\n",
        "    non_edges = list(all_pairs - edges)\n",
        "\n",
        "    # Split edges into validation and test sets\n",
        "    edges = list(edges)\n",
        "    train_edges, temp_edges = train_test_split(edges, test_size=test_size + val_size, random_state=42)\n",
        "    val_edges, test_edges = train_test_split(temp_edges, test_size=test_size / (test_size + val_size), random_state=42)\n",
        "\n",
        "    # Sample non-edges for validation and test sets\n",
        "    num_val_non_edges = len(val_edges)\n",
        "    num_test_non_edges = len(test_edges)\n",
        "\n",
        "    val_non_edges = random.sample(non_edges, num_val_non_edges)\n",
        "    test_non_edges = random.sample(non_edges, num_test_non_edges)\n",
        "    # Recreate the training graph without validation and test edges\n",
        "    train_graph = nx.Graph()\n",
        "    train_graph.add_edges_from(train_edges)\n",
        "    train_graph.add_nodes_from(range(num_nodes))  # Add isolated nodes\n",
        "    train_edge_index = torch.tensor(list(train_graph.edges)).t().contiguous()\n",
        "\n",
        "    # Recreate training edge_index\n",
        "    train_edge_index = torch.tensor(train_edges).t().contiguous()\n",
        "\n",
        "    return train_edge_index, val_edges, test_edges, val_non_edges, test_non_edges,train_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "id": "fe2dd7709dd505aa",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-19T18:30:48.460166Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2dd7709dd505aa",
        "outputId": "ca82a18f-400c-425d-c249-a22de983ed03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train edge index shape: torch.Size([2, 75350])\n",
            "Number of validation edges: 4432\n",
            "Number of test edges: 8866\n",
            "Number of validation non-edges: 4432\n",
            "Number of test non-edges: 8866\n"
          ]
        }
      ],
      "source": [
        "# Extract edge_index and number of nodes\n",
        "edge_index = data.edge_index  # (2, E)\n",
        "num_nodes = data.num_nodes\n",
        "\n",
        "# Split edges and sample non-edges\n",
        "train_edge_index, val_edges, test_edges, val_non_edges, test_non_edges, train_graph = remove_edges_and_sample_optimized(edge_index, num_nodes)\n",
        "\n",
        "print(\"Train edge index shape:\", train_edge_index.shape)\n",
        "print(\"Number of validation edges:\", len(val_edges))\n",
        "print(\"Number of test edges:\", len(test_edges))\n",
        "print(\"Number of validation non-edges:\", len(val_non_edges))\n",
        "print(\"Number of test non-edges:\", len(test_non_edges))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e9b5a1",
      "metadata": {
        "id": "19e9b5a1"
      },
      "source": [
        "#### Normal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmpC-FPNsmd_",
        "outputId": "74e6f1e0-2e33-4620-fc35-225d5035141e"
      },
      "id": "zmpC-FPNsmd_",
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3327, 3327])"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYGh6RE-zop2",
        "outputId": "3a145154-618c-4532-924d-7e09823236c9"
      },
      "id": "EYGh6RE-zop2",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3327, 3327])"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "2e8c80c2",
      "metadata": {
        "id": "2e8c80c2"
      },
      "outputs": [],
      "source": [
        "# Extract train graph adjacency matrix\n",
        "num_n=train_edge_index.max().item() + 1\n",
        "train_adj_matrix = to_dense_adj_custom(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "train_adj_matrix = train_adj_matrix.to(torch.float32)  # Ensure float type for computations\n",
        "\n",
        "train_adj_matrix = train_adj_matrix.clamp(max=1)\n",
        "\n",
        "# Normalize adjacency for training graph\n",
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 32\n",
        "latent_dim = 16\n",
        "model = VGAE(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "model = model.to('cuda')  # Move model to GPU if available\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d22b68",
      "metadata": {
        "id": "58d22b68"
      },
      "source": [
        "#### Weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "6cf72fc1",
      "metadata": {
        "id": "6cf72fc1"
      },
      "outputs": [],
      "source": [
        "# Extract train graph adjacency matrix\n",
        "num_n=train_edge_index.max().item() + 1\n",
        "train_adj_matrix = to_dense_adj_custom(train_edge_index, max_num_nodes=num_n)[0]  # Convert to dense adjacency matrix\n",
        "train_adj_matrix = train_adj_matrix.to(torch.float32)  # Ensure float type for computations\n",
        "\n",
        "train_adj_matrix = train_adj_matrix.clamp(max=1)\n",
        "\n",
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "model = VGAE_W(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "model = model.to('cuda')  # Move model to GPU if available\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "\n",
        "X = torch.eye(num_nodes)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    Z, A_reconstructed, mu, log_sigma = model(X.to('cuda'), A_tilde_train.to('cuda'))\n",
        "\n",
        "    # Debugging: Check for NaNs in the output of the model\n",
        "    if torch.isnan(A_reconstructed).sum() > 0 :\n",
        "        print(\"NaN  detected in A_reconstructed!\")\n",
        "        break\n",
        "    if  torch.isinf(A_reconstructed).sum() > 0:\n",
        "        print(\" Inf detected in A_reconstructed!\")\n",
        "        break\n",
        "\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function(train_adj_matrix.to('cuda'), A_reconstructed.to('cuda'), mu.to('cuda'), log_sigma.to('cuda'))\n",
        "\n",
        "    # Check if loss becomes NaN or Inf\n",
        "    if torch.isnan(loss).sum() > 0 or torch.isinf(loss).sum() > 0:\n",
        "        print(\"NaN or Inf detected in loss!\")\n",
        "        break\n",
        "\n",
        "    # Apply gradient clipping before backward pass\n",
        "    #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss at each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eqkMXd5_unCR",
        "outputId": "53349541-b54b-43b9-d436-0ab385fe9e93"
      },
      "id": "eqkMXd5_unCR",
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 8522986.0\n",
            "Epoch 2, Loss: 8439624.0\n",
            "Epoch 3, Loss: 8373316.5\n",
            "Epoch 4, Loss: 8294545.5\n",
            "Epoch 5, Loss: 8218629.5\n",
            "Epoch 6, Loss: 8172857.5\n",
            "Epoch 7, Loss: 8122834.0\n",
            "Epoch 8, Loss: 8086443.0\n",
            "Epoch 9, Loss: 8047990.5\n",
            "Epoch 10, Loss: 8026068.5\n",
            "Epoch 11, Loss: 7984561.5\n",
            "Epoch 12, Loss: 7984052.5\n",
            "Epoch 13, Loss: 7955595.0\n",
            "Epoch 14, Loss: 7930405.5\n",
            "Epoch 15, Loss: 7928451.5\n",
            "Epoch 16, Loss: 7925911.5\n",
            "Epoch 17, Loss: 7904379.5\n",
            "Epoch 18, Loss: 7913075.5\n",
            "Epoch 19, Loss: 7890591.5\n",
            "Epoch 20, Loss: 7891773.0\n",
            "Epoch 21, Loss: 7887209.0\n",
            "Epoch 22, Loss: 7887262.5\n",
            "Epoch 23, Loss: 7879203.0\n",
            "Epoch 24, Loss: 7872646.0\n",
            "Epoch 25, Loss: 7875378.5\n",
            "Epoch 26, Loss: 7877303.5\n",
            "Epoch 27, Loss: 7868734.5\n",
            "Epoch 28, Loss: 7868485.5\n",
            "Epoch 29, Loss: 7867430.5\n",
            "Epoch 30, Loss: 7867819.0\n",
            "Epoch 31, Loss: 7865159.5\n",
            "Epoch 32, Loss: 7863379.5\n",
            "Epoch 33, Loss: 7865214.5\n",
            "Epoch 34, Loss: 7864693.5\n",
            "Epoch 35, Loss: 7862830.0\n",
            "Epoch 36, Loss: 7861997.0\n",
            "Epoch 37, Loss: 7861716.5\n",
            "Epoch 38, Loss: 7860861.0\n",
            "Epoch 39, Loss: 7859052.5\n",
            "Epoch 40, Loss: 7858901.5\n",
            "Epoch 41, Loss: 7858045.0\n",
            "Epoch 42, Loss: 7858890.0\n",
            "Epoch 43, Loss: 7856244.5\n",
            "Epoch 44, Loss: 7855803.5\n",
            "Epoch 45, Loss: 7856557.5\n",
            "Epoch 46, Loss: 7853084.0\n",
            "Epoch 47, Loss: 7854335.5\n",
            "Epoch 48, Loss: 7853388.5\n",
            "Epoch 49, Loss: 7851478.5\n",
            "Epoch 50, Loss: 7851734.5\n",
            "Epoch 51, Loss: 7850061.0\n",
            "Epoch 52, Loss: 7847858.5\n",
            "Epoch 53, Loss: 7846962.0\n",
            "Epoch 54, Loss: 7848779.0\n",
            "Epoch 55, Loss: 7845924.0\n",
            "Epoch 56, Loss: 7844770.5\n",
            "Epoch 57, Loss: 7843593.5\n",
            "Epoch 58, Loss: 7843460.5\n",
            "Epoch 59, Loss: 7843468.0\n",
            "Epoch 60, Loss: 7842442.0\n",
            "Epoch 61, Loss: 7843344.5\n",
            "Epoch 62, Loss: 7841038.5\n",
            "Epoch 63, Loss: 7840304.0\n",
            "Epoch 64, Loss: 7840234.5\n",
            "Epoch 65, Loss: 7840089.0\n",
            "Epoch 66, Loss: 7839183.0\n",
            "Epoch 67, Loss: 7838974.0\n",
            "Epoch 68, Loss: 7839703.0\n",
            "Epoch 69, Loss: 7838150.5\n",
            "Epoch 70, Loss: 7838439.5\n",
            "Epoch 71, Loss: 7836411.5\n",
            "Epoch 72, Loss: 7834934.0\n",
            "Epoch 73, Loss: 7835214.5\n",
            "Epoch 74, Loss: 7834332.5\n",
            "Epoch 75, Loss: 7834880.5\n",
            "Epoch 76, Loss: 7833412.0\n",
            "Epoch 77, Loss: 7834034.5\n",
            "Epoch 78, Loss: 7833651.0\n",
            "Epoch 79, Loss: 7832597.0\n",
            "Epoch 80, Loss: 7832726.0\n",
            "Epoch 81, Loss: 7832173.5\n",
            "Epoch 82, Loss: 7831644.5\n",
            "Epoch 83, Loss: 7831220.5\n",
            "Epoch 84, Loss: 7831304.5\n",
            "Epoch 85, Loss: 7830481.0\n",
            "Epoch 86, Loss: 7830510.5\n",
            "Epoch 87, Loss: 7828790.5\n",
            "Epoch 88, Loss: 7829232.0\n",
            "Epoch 89, Loss: 7830165.5\n",
            "Epoch 90, Loss: 7827727.5\n",
            "Epoch 91, Loss: 7826682.5\n",
            "Epoch 92, Loss: 7827956.0\n",
            "Epoch 93, Loss: 7825891.0\n",
            "Epoch 94, Loss: 7827416.0\n",
            "Epoch 95, Loss: 7825314.0\n",
            "Epoch 96, Loss: 7826377.5\n",
            "Epoch 97, Loss: 7826169.5\n",
            "Epoch 98, Loss: 7825127.5\n",
            "Epoch 99, Loss: 7824882.0\n",
            "Epoch 100, Loss: 7824133.5\n",
            "Epoch 101, Loss: 7823803.5\n",
            "Epoch 102, Loss: 7823153.0\n",
            "Epoch 103, Loss: 7822686.0\n",
            "Epoch 104, Loss: 7822070.5\n",
            "Epoch 105, Loss: 7822416.0\n",
            "Epoch 106, Loss: 7821248.0\n",
            "Epoch 107, Loss: 7820947.0\n",
            "Epoch 108, Loss: 7821613.0\n",
            "Epoch 109, Loss: 7821976.0\n",
            "Epoch 110, Loss: 7821484.0\n",
            "Epoch 111, Loss: 7821291.5\n",
            "Epoch 112, Loss: 7820429.0\n",
            "Epoch 113, Loss: 7819697.5\n",
            "Epoch 114, Loss: 7819050.0\n",
            "Epoch 115, Loss: 7819514.0\n",
            "Epoch 116, Loss: 7818803.0\n",
            "Epoch 117, Loss: 7818111.5\n",
            "Epoch 118, Loss: 7818075.5\n",
            "Epoch 119, Loss: 7818520.0\n",
            "Epoch 120, Loss: 7817691.5\n",
            "Epoch 121, Loss: 7817742.0\n",
            "Epoch 122, Loss: 7816742.5\n",
            "Epoch 123, Loss: 7817272.0\n",
            "Epoch 124, Loss: 7815695.0\n",
            "Epoch 125, Loss: 7815625.5\n",
            "Epoch 126, Loss: 7815208.0\n",
            "Epoch 127, Loss: 7815104.5\n",
            "Epoch 128, Loss: 7814913.0\n",
            "Epoch 129, Loss: 7813993.5\n",
            "Epoch 130, Loss: 7814881.5\n",
            "Epoch 131, Loss: 7815380.0\n",
            "Epoch 132, Loss: 7813464.0\n",
            "Epoch 133, Loss: 7813834.0\n",
            "Epoch 134, Loss: 7813680.0\n",
            "Epoch 135, Loss: 7813747.5\n",
            "Epoch 136, Loss: 7812616.5\n",
            "Epoch 137, Loss: 7811561.0\n",
            "Epoch 138, Loss: 7812109.5\n",
            "Epoch 139, Loss: 7811076.0\n",
            "Epoch 140, Loss: 7811517.0\n",
            "Epoch 141, Loss: 7811479.5\n",
            "Epoch 142, Loss: 7811403.5\n",
            "Epoch 143, Loss: 7810908.0\n",
            "Epoch 144, Loss: 7809834.0\n",
            "Epoch 145, Loss: 7810543.0\n",
            "Epoch 146, Loss: 7810264.5\n",
            "Epoch 147, Loss: 7809599.5\n",
            "Epoch 148, Loss: 7809116.5\n",
            "Epoch 149, Loss: 7808976.5\n",
            "Epoch 150, Loss: 7808382.5\n",
            "Epoch 151, Loss: 7808469.0\n",
            "Epoch 152, Loss: 7809471.0\n",
            "Epoch 153, Loss: 7808325.0\n",
            "Epoch 154, Loss: 7808069.5\n",
            "Epoch 155, Loss: 7807744.0\n",
            "Epoch 156, Loss: 7806384.0\n",
            "Epoch 157, Loss: 7807351.0\n",
            "Epoch 158, Loss: 7806496.5\n",
            "Epoch 159, Loss: 7806632.5\n",
            "Epoch 160, Loss: 7806970.5\n",
            "Epoch 161, Loss: 7807221.5\n",
            "Epoch 162, Loss: 7805359.0\n",
            "Epoch 163, Loss: 7805894.5\n",
            "Epoch 164, Loss: 7805731.0\n",
            "Epoch 165, Loss: 7805424.0\n",
            "Epoch 166, Loss: 7805156.0\n",
            "Epoch 167, Loss: 7804458.5\n",
            "Epoch 168, Loss: 7804993.5\n",
            "Epoch 169, Loss: 7805071.5\n",
            "Epoch 170, Loss: 7804190.5\n",
            "Epoch 171, Loss: 7805359.0\n",
            "Epoch 172, Loss: 7804179.5\n",
            "Epoch 173, Loss: 7804642.0\n",
            "Epoch 174, Loss: 7804109.0\n",
            "Epoch 175, Loss: 7803207.5\n",
            "Epoch 176, Loss: 7803205.5\n",
            "Epoch 177, Loss: 7803275.5\n",
            "Epoch 178, Loss: 7801852.5\n",
            "Epoch 179, Loss: 7803005.5\n",
            "Epoch 180, Loss: 7801958.0\n",
            "Epoch 181, Loss: 7802005.0\n",
            "Epoch 182, Loss: 7801705.5\n",
            "Epoch 183, Loss: 7801129.5\n",
            "Epoch 184, Loss: 7801520.5\n",
            "Epoch 185, Loss: 7800815.5\n",
            "Epoch 186, Loss: 7800545.0\n",
            "Epoch 187, Loss: 7801422.0\n",
            "Epoch 188, Loss: 7800556.5\n",
            "Epoch 189, Loss: 7800445.0\n",
            "Epoch 190, Loss: 7800237.5\n",
            "Epoch 191, Loss: 7799443.5\n",
            "Epoch 192, Loss: 7799901.0\n",
            "Epoch 193, Loss: 7799542.5\n",
            "Epoch 194, Loss: 7798965.0\n",
            "Epoch 195, Loss: 7798921.0\n",
            "Epoch 196, Loss: 7799354.0\n",
            "Epoch 197, Loss: 7798288.0\n",
            "Epoch 198, Loss: 7797347.5\n",
            "Epoch 199, Loss: 7797827.5\n",
            "Epoch 200, Loss: 7798010.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51d4edf",
      "metadata": {
        "id": "f51d4edf"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "da1f61f9",
      "metadata": {
        "id": "da1f61f9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "# Assume edge_index, num_nodes, and remove_edges_and_sample_optimized are defined\n",
        "# Extract train graph adjacency matrix\n",
        "num_n=train_edge_index.max().item() + 1\n",
        "train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_n)[0]  # Convert to dense adjacency matrix\n",
        "train_adj_matrix = train_adj_matrix.to(torch.float32)  # Ensure float type for computations\n",
        "train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "# Convert to SciPy sparse matrix\n",
        "# Create the adjacency matrix from the edge list (train_edge_index)\n",
        "#train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "\n",
        "# Enforce symmetry (add the transpose to ensure both directions are captured)\n",
        "train_adj_matrix = train_adj_matrix + train_adj_matrix.T\n",
        "\n",
        "# Ensure that the diagonal entries are 1 (self-loops)\n",
        "train_adj_matrix.fill_diagonal_(1.0)\n",
        "train_adj_matrix = train_adj_matrix.clamp(max=1)\n",
        "# Node features\n",
        "if data.x is not None:\n",
        "    X = data.x  # Use provided node features\n",
        "else:\n",
        "    X = torch.eye(num_nodes)  # Use identity matrix if featureless\n",
        "\n",
        "# Normalize adjacency for training graph\n",
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "model = VGAE_MLP(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "model = model.to('cuda')  # Move model to GPU if available\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "b891643b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "b891643b",
        "outputId": "fa5b4fe4-0e7d-4908-8ec5-17ba0919d4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([126842])\n",
            "Epoch 1, Loss: 6154940928.0\n",
            "torch.Size([126842])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-1bf173104269>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_adj_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_reconstructed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_edge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    Z, A_reconstructed, mu, log_sigma = model(X.to('cuda'), A_tilde_train.to('cuda'), edge_index=edge_index)\n",
        "\n",
        "    # Clamp log_sigma to prevent extreme values\n",
        "    log_sigma = torch.clamp(log_sigma, min=-18, max=18)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function_mlp(train_adj_matrix.to('cuda'), A_reconstructed, mu, log_sigma, train_edge_index.to('cuda'))\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d56e73",
      "metadata": {
        "id": "76d56e73"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "6a5806d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a5806d8",
        "outputId": "5c368dd0-d1ec-467e-c48b-35cfe2094ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-254-a034f13ef9ad>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
            "<ipython-input-254-a034f13ef9ad>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A_reconstructed = A_reconstructed.detach().cpu()\n",
        "\n",
        "# Ensure test edges and non-edges are tensors\n",
        "test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
        "test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n",
        "\n",
        "# Handle different decoder outputs\n",
        "if A_reconstructed.dim() == 2:\n",
        "    # If A_reconstructed is a full adjacency matrix\n",
        "    test_edge_scores = A_reconstructed[test_edges[:, 0], test_edges[:, 1]].numpy()\n",
        "    test_non_edge_scores = A_reconstructed[test_non_edges[:, 0], test_non_edges[:, 1]].numpy()\n",
        "else:\n",
        "    # If A_reconstructed is a 1D tensor (edge probabilities only)\n",
        "    test_edge_scores = A_reconstructed[:len(test_edges)].numpy()\n",
        "    test_non_edge_scores = A_reconstructed[len(test_edges):].numpy()\n",
        "\n",
        "# Combine scores and create labels\n",
        "scores = np.concatenate([test_edge_scores, test_non_edge_scores])\n",
        "labels = np.concatenate([np.ones(len(test_edge_scores)), np.zeros(len(test_non_edge_scores))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "506bc5cc0e958f4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "506bc5cc0e958f4f",
        "outputId": "f0759142-1f5b-4677-caec-f5853e9f2feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.6329530160099577\n"
          ]
        }
      ],
      "source": [
        "\n",
        "roc_auc = roc_auc_score(labels, scores)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "70a1c196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70a1c196",
        "outputId": "7ce7999d-35d2-420c-b336-4ac12734e9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision (AP): 0.6490\n"
          ]
        }
      ],
      "source": [
        "ap_score = average_precision_score(labels, scores)\n",
        "print(f\"Average Precision (AP): {ap_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ff2f59",
      "metadata": {
        "id": "89ff2f59"
      },
      "source": [
        "### Patent dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cfdbe733",
      "metadata": {
        "id": "cfdbe733"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import save_npz, load_npz\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.sparse import coo_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "A = load_npz(\"combined_adj_small.npz\")\n",
        "X = load_npz(\"combined_features_matrix.npz\")\n",
        "\n",
        "X = torch.tensor(X.toarray(), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1f7bb7d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7bb7d9",
        "outputId": "c901813a-f246-44a5-e70f-af7d73a434bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A is symmetric.\n"
          ]
        }
      ],
      "source": [
        "# Check if the matrix is symmetric\n",
        "if (A != A.T).nnz == 0:  # If the number of non-zero elements in (A - A.T) is zero\n",
        "    print(\"Matrix A is symmetric.\")\n",
        "else:\n",
        "    print(\"Matrix A is not symmetric.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJpXL5sAmwy_",
        "outputId": "d9ab604a-073d-4add-d8e1-79fd077f6d0d"
      },
      "id": "yJpXL5sAmwy_",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0367, -0.0003, -0.0465,  ...,  0.0678, -0.0619, -0.0571],\n",
              "        [-0.0490, -0.0121, -0.0688,  ...,  0.1723,  0.0379, -0.0342],\n",
              "        [-0.0546, -0.0845, -0.1177,  ...,  0.0683,  0.0276, -0.0078],\n",
              "        ...,\n",
              "        [-0.0380,  0.0360,  0.0635,  ...,  0.0293,  0.0540,  0.0328],\n",
              "        [-0.1023,  0.0321, -0.0490,  ..., -0.0618,  0.0613,  0.0230],\n",
              "        [-0.1295,  0.0772, -0.0172,  ..., -0.0530,  0.0565,  0.0502]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c0f48d2c",
      "metadata": {
        "id": "c0f48d2c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def split_edges_and_sample(A, num_samples=None, test_size=0.1, val_size=0.05, random_state=42):\n",
        "    \"\"\"\n",
        "    Efficiently splits edges and samples non-edges.\n",
        "\n",
        "    Parameters:\n",
        "    - A: scipy.sparse.coo_matrix (adjacency matrix)\n",
        "    - num_samples: Number of non-edges to sample (adjust based on graph size)\n",
        "    - test_size: Proportion of edges/non-edges for testing\n",
        "    - val_size: Proportion of edges/non-edges for validation\n",
        "    - random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - train_edge_index: Edge list for training\n",
        "    - val_edges, test_edges: Validation and test edge lists\n",
        "    - val_non_edges, test_non_edges: Validation and test non-edges\n",
        "    - train_graph: Sparse matrix representing the training graph\n",
        "    \"\"\"\n",
        "    A_coo = coo_matrix(A)\n",
        "    edges = np.vstack((A_coo.row, A_coo.col)).T  # Extract edges\n",
        "    num_nodes = A.shape[0]\n",
        "\n",
        "    # Convert edges to a set for fast lookup\n",
        "    existing_edges = set(map(tuple, edges))\n",
        "    num_samples=len(edges)*0.15\n",
        "    # Randomly sample non-edges\n",
        "    np.random.seed(random_state)\n",
        "    non_edges = set()\n",
        "    while len(non_edges) < num_samples:\n",
        "        i = np.random.randint(0, num_nodes)\n",
        "        j = np.random.randint(0, num_nodes)\n",
        "        if i != j and (i, j) not in existing_edges and (j, i) not in existing_edges:\n",
        "            non_edges.add((i, j))\n",
        "    #print(existing_edges)\n",
        "    non_edges = np.array(list(non_edges))\n",
        "\n",
        "    # Split edges into train, validation, and test sets\n",
        "    train_edges, temp_edges = train_test_split(edges, test_size=(test_size + val_size), random_state=random_state)\n",
        "\n",
        "    val_edges, test_edges = train_test_split(temp_edges, test_size=(test_size / (test_size + val_size)), random_state=random_state)\n",
        "\n",
        "    # Split sampled non-edges into validation and test sets\n",
        "    val_non_edges, test_non_edges = train_test_split(non_edges, test_size=(test_size / (test_size + val_size)), random_state=random_state)\n",
        "\n",
        "    # Create a training graph (without val/test edges)\n",
        "    train_graph = coo_matrix(\n",
        "        (np.ones(len(train_edges)), (train_edges[:, 0], train_edges[:, 1])),\n",
        "        shape=A.shape\n",
        "    )\n",
        "    train_graph = train_graph + train_graph.T  # Ensure symmetry\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_edge_index = torch.tensor(train_edges.T, dtype=torch.long)\n",
        "    val_edges = torch.tensor(val_edges, dtype=torch.long)\n",
        "    test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
        "    val_non_edges = torch.tensor(val_non_edges, dtype=torch.long)\n",
        "    test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n",
        "\n",
        "    return train_edge_index, val_edges, test_edges, val_non_edges, test_non_edges, train_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "90308834",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90308834",
        "outputId": "4968bced-2116-48a7-a890-7ef0582624e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train edge index shape: torch.Size([2, 44438])\n",
            "Number of validation edges: 2614\n",
            "Number of test edges: 5229\n",
            "Number of validation non-edges: 2614\n",
            "Number of test non-edges: 5229\n"
          ]
        }
      ],
      "source": [
        "#A = A + A.T  # Ensure symmetry for an undirected graph\n",
        "#A[A > 1] = 1  # Remove duplicate edges\n",
        "\n",
        "# Split edges and sample non-edges\n",
        "train_edge_index, val_edges, test_edges, val_non_edges, test_non_edges, train_graph= split_edges_and_sample(A)\n",
        "\n",
        "print(\"Train edge index shape:\", train_edge_index.shape)\n",
        "print(\"Number of validation edges:\", len(val_edges))\n",
        "print(\"Number of test edges:\", len(test_edges))\n",
        "print(\"Number of validation non-edges:\", len(val_non_edges))\n",
        "print(\"Number of test non-edges:\", len(test_non_edges))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c7dc394c",
      "metadata": {
        "id": "c7dc394c"
      },
      "outputs": [],
      "source": [
        "def normalize_adjacency_sparse_gpu(A):\n",
        "    \"\"\"\n",
        "    Normalize adjacency matrix on GPU using sparse matrices.\n",
        "    A: Sparse adjacency matrix (torch.sparse.FloatTensor).\n",
        "    \"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    A = A.to(device)  # Move to GPU if available\n",
        "\n",
        "    # Ensure self-loops (can be done with sparse matrices too)\n",
        "    #eye = torch.eye(A.size(0), device=A.device).to_sparse()\n",
        "    #A = A + eye\n",
        "\n",
        "    # Degree vector (sparse sum)\n",
        "    row_sum = torch.sum(A, dim=1) # Sparse sum and convert to dense\n",
        "\n",
        "    # Avoid division by zero by adding a small epsilon\n",
        "    D_inv_sqrt = torch.diag(1.0 / torch.sqrt(row_sum + 1e-10))\n",
        "\n",
        "    # Normalize adjacency\n",
        "    normalized_A = D_inv_sqrt @ A @ D_inv_sqrt\n",
        "\n",
        "    # Enforce symmetry\n",
        "    normalized_A = (normalized_A + normalized_A.T) / 2.0\n",
        "\n",
        "    return normalized_A\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f10bfa28",
      "metadata": {
        "id": "f10bfa28"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9588794c",
      "metadata": {
        "id": "9588794c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#import torch_sparse\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "# Assume edge_index, num_nodes, and remove_edges_and_sample_optimized are defined\n",
        "# Extract train graph adjacency matrix\n",
        "\n",
        "# Extract train graph adjacency matrix\n",
        "num_nodes =  max(train_edge_index[0].max(), train_edge_index[1].max()) + 1\n",
        "\n",
        "\n",
        "train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "# Convert to SciPy sparse matrix\n",
        "\n",
        "\n",
        "#train_adj_matrix = to_scipy_sparse_matrix(train_edge_index, num_nodes=num_nodes)\n",
        "# Ensure adjacency matrix is sparse on GPU\n",
        "train_adj_matrix = train_adj_matrix.to('cuda')  # Move sparse matrix to GPU\n",
        "\n",
        "# Convert directly to a PyTorch sparse tensor\n",
        "#train_adj_matrix = torch.tensor(train_adj_matrix.toarray(), dtype=torch.float32)\n",
        "# Ensure adjacency matrix is sparse on GPU\n",
        "#train_adj_matrix = train_adj_matrix.to_sparse().to('cuda')  # Move sparse matrix to GPU\n",
        "#train_adj_matrix = torch.sparse_coo_tensor(indices, values, size=(num_nodes, num_nodes), dtype=torch.float32).to(device)\n",
        "\n",
        "# Normalize adjacency for training graph\n",
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix.to(torch.float32))  # Normalize\n",
        "\n",
        "#train_adj_matrix = train_adj_matrix.to('cuda')\n",
        "#A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix)\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 32\n",
        "latent_dim = 16\n",
        "model = VGAE_MLP(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "model = model.to('cuda')  # Move model to GPU if available\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7a1894b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7a1894b4",
        "outputId": "2a277da3-84d9-43a0-c96b-7a2c574ed277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([44438])\n",
            "Epoch 1, Loss: 11628205.0\n",
            "torch.Size([44438])\n",
            "Epoch 2, Loss: 11194987.0\n",
            "torch.Size([44438])\n",
            "Epoch 3, Loss: 10772963.0\n",
            "torch.Size([44438])\n",
            "Epoch 4, Loss: 10367990.0\n",
            "torch.Size([44438])\n",
            "Epoch 5, Loss: 9977155.0\n",
            "torch.Size([44438])\n",
            "Epoch 6, Loss: 9607456.0\n",
            "torch.Size([44438])\n",
            "Epoch 7, Loss: 9240159.0\n",
            "torch.Size([44438])\n",
            "Epoch 8, Loss: 8882024.0\n",
            "torch.Size([44438])\n",
            "Epoch 9, Loss: 8530211.0\n",
            "torch.Size([44438])\n",
            "Epoch 10, Loss: 8196824.0\n",
            "torch.Size([44438])\n",
            "Epoch 11, Loss: 7889602.0\n",
            "torch.Size([44438])\n",
            "Epoch 12, Loss: 7605178.5\n",
            "torch.Size([44438])\n",
            "Epoch 13, Loss: 7334371.5\n",
            "torch.Size([44438])\n",
            "Epoch 14, Loss: 7078561.5\n",
            "torch.Size([44438])\n",
            "Epoch 15, Loss: 6840553.5\n",
            "torch.Size([44438])\n",
            "Epoch 16, Loss: 6620122.5\n",
            "torch.Size([44438])\n",
            "Epoch 17, Loss: 6413637.5\n",
            "torch.Size([44438])\n",
            "Epoch 18, Loss: 6214259.0\n",
            "torch.Size([44438])\n",
            "Epoch 19, Loss: 6023259.0\n",
            "torch.Size([44438])\n",
            "Epoch 20, Loss: 5838478.5\n",
            "torch.Size([44438])\n",
            "Epoch 21, Loss: 5656990.5\n",
            "torch.Size([44438])\n",
            "Epoch 22, Loss: 5482401.0\n",
            "torch.Size([44438])\n",
            "Epoch 23, Loss: 5313881.5\n",
            "torch.Size([44438])\n",
            "Epoch 24, Loss: 5151717.5\n",
            "torch.Size([44438])\n",
            "Epoch 25, Loss: 5000519.0\n",
            "torch.Size([44438])\n",
            "Epoch 26, Loss: 4858466.5\n",
            "torch.Size([44438])\n",
            "Epoch 27, Loss: 4716786.5\n",
            "torch.Size([44438])\n",
            "Epoch 28, Loss: 4579445.5\n",
            "torch.Size([44438])\n",
            "Epoch 29, Loss: 4448222.0\n",
            "torch.Size([44438])\n",
            "Epoch 30, Loss: 4323856.5\n",
            "torch.Size([44438])\n",
            "Epoch 31, Loss: 4203557.5\n",
            "torch.Size([44438])\n",
            "Epoch 32, Loss: 4084531.5\n",
            "torch.Size([44438])\n",
            "Epoch 33, Loss: 3972176.5\n",
            "torch.Size([44438])\n",
            "Epoch 34, Loss: 3864899.75\n",
            "torch.Size([44438])\n",
            "Epoch 35, Loss: 3762976.25\n",
            "torch.Size([44438])\n",
            "Epoch 36, Loss: 3665481.25\n",
            "torch.Size([44438])\n",
            "Epoch 37, Loss: 3576121.0\n",
            "torch.Size([44438])\n",
            "Epoch 38, Loss: 3491034.25\n",
            "torch.Size([44438])\n",
            "Epoch 39, Loss: 3408613.25\n",
            "torch.Size([44438])\n",
            "Epoch 40, Loss: 3328804.5\n",
            "torch.Size([44438])\n",
            "Epoch 41, Loss: 3251024.25\n",
            "torch.Size([44438])\n",
            "Epoch 42, Loss: 3173936.25\n",
            "torch.Size([44438])\n",
            "Epoch 43, Loss: 3098982.75\n",
            "torch.Size([44438])\n",
            "Epoch 44, Loss: 3027957.5\n",
            "torch.Size([44438])\n",
            "Epoch 45, Loss: 2956338.0\n",
            "torch.Size([44438])\n",
            "Epoch 46, Loss: 2885680.5\n",
            "torch.Size([44438])\n",
            "Epoch 47, Loss: 2817898.25\n",
            "torch.Size([44438])\n",
            "Epoch 48, Loss: 2753369.0\n",
            "torch.Size([44438])\n",
            "Epoch 49, Loss: 2692445.0\n",
            "torch.Size([44438])\n",
            "Epoch 50, Loss: 2635085.75\n",
            "torch.Size([44438])\n",
            "Epoch 51, Loss: 2579547.25\n",
            "torch.Size([44438])\n",
            "Epoch 52, Loss: 2525009.5\n",
            "torch.Size([44438])\n",
            "Epoch 53, Loss: 2473224.5\n",
            "torch.Size([44438])\n",
            "Epoch 54, Loss: 2424986.75\n",
            "torch.Size([44438])\n",
            "Epoch 55, Loss: 2380168.5\n",
            "torch.Size([44438])\n",
            "Epoch 56, Loss: 2337224.0\n",
            "torch.Size([44438])\n",
            "Epoch 57, Loss: 2296787.25\n",
            "torch.Size([44438])\n",
            "Epoch 58, Loss: 2258359.0\n",
            "torch.Size([44438])\n",
            "Epoch 59, Loss: 2220934.0\n",
            "torch.Size([44438])\n",
            "Epoch 60, Loss: 2185864.25\n",
            "torch.Size([44438])\n",
            "Epoch 61, Loss: 2148038.5\n",
            "torch.Size([44438])\n",
            "Epoch 62, Loss: 2107184.25\n",
            "torch.Size([44438])\n",
            "Epoch 63, Loss: 2067775.875\n",
            "torch.Size([44438])\n",
            "Epoch 64, Loss: 2028372.375\n",
            "torch.Size([44438])\n",
            "Epoch 65, Loss: 1990738.75\n",
            "torch.Size([44438])\n",
            "Epoch 66, Loss: 1953409.5\n",
            "torch.Size([44438])\n",
            "Epoch 67, Loss: 1917707.5\n",
            "torch.Size([44438])\n",
            "Epoch 68, Loss: 1884425.5\n",
            "torch.Size([44438])\n",
            "Epoch 69, Loss: 1852064.625\n",
            "torch.Size([44438])\n",
            "Epoch 70, Loss: 1820796.5\n",
            "torch.Size([44438])\n",
            "Epoch 71, Loss: 1789013.25\n",
            "torch.Size([44438])\n",
            "Epoch 72, Loss: 1758381.0\n",
            "torch.Size([44438])\n",
            "Epoch 73, Loss: 1727122.125\n",
            "torch.Size([44438])\n",
            "Epoch 74, Loss: 1697963.25\n",
            "torch.Size([44438])\n",
            "Epoch 75, Loss: 1669373.25\n",
            "torch.Size([44438])\n",
            "Epoch 76, Loss: 1638371.625\n",
            "torch.Size([44438])\n",
            "Epoch 77, Loss: 1605911.25\n",
            "torch.Size([44438])\n",
            "Epoch 78, Loss: 1575186.75\n",
            "torch.Size([44438])\n",
            "Epoch 79, Loss: 1545478.25\n",
            "torch.Size([44438])\n",
            "Epoch 80, Loss: 1517663.375\n",
            "torch.Size([44438])\n",
            "Epoch 81, Loss: 1490575.625\n",
            "torch.Size([44438])\n",
            "Epoch 82, Loss: 1463825.5\n",
            "torch.Size([44438])\n",
            "Epoch 83, Loss: 1436975.125\n",
            "torch.Size([44438])\n",
            "Epoch 84, Loss: 1411357.625\n",
            "torch.Size([44438])\n",
            "Epoch 85, Loss: 1386611.625\n",
            "torch.Size([44438])\n",
            "Epoch 86, Loss: 1362731.625\n",
            "torch.Size([44438])\n",
            "Epoch 87, Loss: 1339161.0\n",
            "torch.Size([44438])\n",
            "Epoch 88, Loss: 1315289.25\n",
            "torch.Size([44438])\n",
            "Epoch 89, Loss: 1290950.875\n",
            "torch.Size([44438])\n",
            "Epoch 90, Loss: 1267290.375\n",
            "torch.Size([44438])\n",
            "Epoch 91, Loss: 1242811.75\n",
            "torch.Size([44438])\n",
            "Epoch 92, Loss: 1217269.375\n",
            "torch.Size([44438])\n",
            "Epoch 93, Loss: 1190368.25\n",
            "torch.Size([44438])\n",
            "Epoch 94, Loss: 1165324.0\n",
            "torch.Size([44438])\n",
            "Epoch 95, Loss: 1139962.375\n",
            "torch.Size([44438])\n",
            "Epoch 96, Loss: 1116009.125\n",
            "torch.Size([44438])\n",
            "Epoch 97, Loss: 1093090.125\n",
            "torch.Size([44438])\n",
            "Epoch 98, Loss: 1071708.75\n",
            "torch.Size([44438])\n",
            "Epoch 99, Loss: 1052153.875\n",
            "torch.Size([44438])\n",
            "Epoch 100, Loss: 1033204.9375\n",
            "torch.Size([44438])\n",
            "Epoch 101, Loss: 1012840.0\n",
            "torch.Size([44438])\n",
            "Epoch 102, Loss: 992935.0625\n",
            "torch.Size([44438])\n",
            "Epoch 103, Loss: 973956.0\n",
            "torch.Size([44438])\n",
            "Epoch 104, Loss: 955979.125\n",
            "torch.Size([44438])\n",
            "Epoch 105, Loss: 937065.0625\n",
            "torch.Size([44438])\n",
            "Epoch 106, Loss: 919597.375\n",
            "torch.Size([44438])\n",
            "Epoch 107, Loss: 901659.25\n",
            "torch.Size([44438])\n",
            "Epoch 108, Loss: 884466.75\n",
            "torch.Size([44438])\n",
            "Epoch 109, Loss: 868406.25\n",
            "torch.Size([44438])\n",
            "Epoch 110, Loss: 853629.1875\n",
            "torch.Size([44438])\n",
            "Epoch 111, Loss: 838930.875\n",
            "torch.Size([44438])\n",
            "Epoch 112, Loss: 825733.4375\n",
            "torch.Size([44438])\n",
            "Epoch 113, Loss: 813405.5625\n",
            "torch.Size([44438])\n",
            "Epoch 114, Loss: 801811.1875\n",
            "torch.Size([44438])\n",
            "Epoch 115, Loss: 790185.8125\n",
            "torch.Size([44438])\n",
            "Epoch 116, Loss: 778236.9375\n",
            "torch.Size([44438])\n",
            "Epoch 117, Loss: 767443.6875\n",
            "torch.Size([44438])\n",
            "Epoch 118, Loss: 758064.8125\n",
            "torch.Size([44438])\n",
            "Epoch 119, Loss: 747007.625\n",
            "torch.Size([44438])\n",
            "Epoch 120, Loss: 737008.0625\n",
            "torch.Size([44438])\n",
            "Epoch 121, Loss: 727079.125\n",
            "torch.Size([44438])\n",
            "Epoch 122, Loss: 716794.1875\n",
            "torch.Size([44438])\n",
            "Epoch 123, Loss: 707410.375\n",
            "torch.Size([44438])\n",
            "Epoch 124, Loss: 696013.25\n",
            "torch.Size([44438])\n",
            "Epoch 125, Loss: 684177.6875\n",
            "torch.Size([44438])\n",
            "Epoch 126, Loss: 673724.25\n",
            "torch.Size([44438])\n",
            "Epoch 127, Loss: 663793.5\n",
            "torch.Size([44438])\n",
            "Epoch 128, Loss: 654634.375\n",
            "torch.Size([44438])\n",
            "Epoch 129, Loss: 646669.8125\n",
            "torch.Size([44438])\n",
            "Epoch 130, Loss: 639116.8125\n",
            "torch.Size([44438])\n",
            "Epoch 131, Loss: 632681.375\n",
            "torch.Size([44438])\n",
            "Epoch 132, Loss: 626143.3125\n",
            "torch.Size([44438])\n",
            "Epoch 133, Loss: 620160.25\n",
            "torch.Size([44438])\n",
            "Epoch 134, Loss: 614829.1875\n",
            "torch.Size([44438])\n",
            "Epoch 135, Loss: 609018.1875\n",
            "torch.Size([44438])\n",
            "Epoch 136, Loss: 603371.875\n",
            "torch.Size([44438])\n",
            "Epoch 137, Loss: 598196.5\n",
            "torch.Size([44438])\n",
            "Epoch 138, Loss: 592720.75\n",
            "torch.Size([44438])\n",
            "Epoch 139, Loss: 587506.5625\n",
            "torch.Size([44438])\n",
            "Epoch 140, Loss: 582343.625\n",
            "torch.Size([44438])\n",
            "Epoch 141, Loss: 576921.0\n",
            "torch.Size([44438])\n",
            "Epoch 142, Loss: 571840.0625\n",
            "torch.Size([44438])\n",
            "Epoch 143, Loss: 566770.625\n",
            "torch.Size([44438])\n",
            "Epoch 144, Loss: 561941.4375\n",
            "torch.Size([44438])\n",
            "Epoch 145, Loss: 557161.125\n",
            "torch.Size([44438])\n",
            "Epoch 146, Loss: 552618.9375\n",
            "torch.Size([44438])\n",
            "Epoch 147, Loss: 548268.1875\n",
            "torch.Size([44438])\n",
            "Epoch 148, Loss: 543780.75\n",
            "torch.Size([44438])\n",
            "Epoch 149, Loss: 539722.0\n",
            "torch.Size([44438])\n",
            "Epoch 150, Loss: 535698.6875\n",
            "torch.Size([44438])\n",
            "Epoch 151, Loss: 532098.0625\n",
            "torch.Size([44438])\n",
            "Epoch 152, Loss: 528277.25\n",
            "torch.Size([44438])\n",
            "Epoch 153, Loss: 524739.6875\n",
            "torch.Size([44438])\n",
            "Epoch 154, Loss: 521157.59375\n",
            "torch.Size([44438])\n",
            "Epoch 155, Loss: 517794.5625\n",
            "torch.Size([44438])\n",
            "Epoch 156, Loss: 514813.6875\n",
            "torch.Size([44438])\n",
            "Epoch 157, Loss: 511688.15625\n",
            "torch.Size([44438])\n",
            "Epoch 158, Loss: 508434.21875\n",
            "torch.Size([44438])\n",
            "Epoch 159, Loss: 505364.125\n",
            "torch.Size([44438])\n",
            "Epoch 160, Loss: 502106.5625\n",
            "torch.Size([44438])\n",
            "Epoch 161, Loss: 498423.21875\n",
            "torch.Size([44438])\n",
            "Epoch 162, Loss: 495212.90625\n",
            "torch.Size([44438])\n",
            "Epoch 163, Loss: 491689.53125\n",
            "torch.Size([44438])\n",
            "Epoch 164, Loss: 487799.5625\n",
            "torch.Size([44438])\n",
            "Epoch 165, Loss: 484114.3125\n",
            "torch.Size([44438])\n",
            "Epoch 166, Loss: 480280.65625\n",
            "torch.Size([44438])\n",
            "Epoch 167, Loss: 476546.4375\n",
            "torch.Size([44438])\n",
            "Epoch 168, Loss: 472786.8125\n",
            "torch.Size([44438])\n",
            "Epoch 169, Loss: 469225.59375\n",
            "torch.Size([44438])\n",
            "Epoch 170, Loss: 465017.625\n",
            "torch.Size([44438])\n",
            "Epoch 171, Loss: 460849.25\n",
            "torch.Size([44438])\n",
            "Epoch 172, Loss: 456683.375\n",
            "torch.Size([44438])\n",
            "Epoch 173, Loss: 452723.46875\n",
            "torch.Size([44438])\n",
            "Epoch 174, Loss: 448840.03125\n",
            "torch.Size([44438])\n",
            "Epoch 175, Loss: 445241.5625\n",
            "torch.Size([44438])\n",
            "Epoch 176, Loss: 441739.40625\n",
            "torch.Size([44438])\n",
            "Epoch 177, Loss: 438266.34375\n",
            "torch.Size([44438])\n",
            "Epoch 178, Loss: 434978.34375\n",
            "torch.Size([44438])\n",
            "Epoch 179, Loss: 431902.09375\n",
            "torch.Size([44438])\n",
            "Epoch 180, Loss: 428938.71875\n",
            "torch.Size([44438])\n",
            "Epoch 181, Loss: 426097.40625\n",
            "torch.Size([44438])\n",
            "Epoch 182, Loss: 423413.40625\n",
            "torch.Size([44438])\n",
            "Epoch 183, Loss: 420978.71875\n",
            "torch.Size([44438])\n",
            "Epoch 184, Loss: 418329.0\n",
            "torch.Size([44438])\n",
            "Epoch 185, Loss: 416065.15625\n",
            "torch.Size([44438])\n",
            "Epoch 186, Loss: 413677.0\n",
            "torch.Size([44438])\n",
            "Epoch 187, Loss: 410812.75\n",
            "torch.Size([44438])\n",
            "Epoch 188, Loss: 407634.0\n",
            "torch.Size([44438])\n",
            "Epoch 189, Loss: 404528.9375\n",
            "torch.Size([44438])\n",
            "Epoch 190, Loss: 401266.125\n",
            "torch.Size([44438])\n",
            "Epoch 191, Loss: 397759.71875\n",
            "torch.Size([44438])\n",
            "Epoch 192, Loss: 394153.3125\n",
            "torch.Size([44438])\n",
            "Epoch 193, Loss: 390780.0\n",
            "torch.Size([44438])\n",
            "Epoch 194, Loss: 387418.78125\n",
            "torch.Size([44438])\n",
            "Epoch 195, Loss: 384279.84375\n",
            "torch.Size([44438])\n",
            "Epoch 196, Loss: 381238.75\n",
            "torch.Size([44438])\n",
            "Epoch 197, Loss: 378465.46875\n",
            "torch.Size([44438])\n",
            "Epoch 198, Loss: 375795.65625\n",
            "torch.Size([44438])\n",
            "Epoch 199, Loss: 373191.1875\n",
            "torch.Size([44438])\n",
            "Epoch 200, Loss: 370689.71875\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    Z, A_reconstructed, mu, log_sigma = model(X.to('cuda'), A_tilde_train.to('cuda'), edge_index=train_edge_index)\n",
        "\n",
        "    # Clamp log_sigma to prevent extreme values\n",
        "    log_sigma = torch.clamp(log_sigma, min=-14, max=14)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function_mlp(train_adj_matrix.to('cuda'), A_reconstructed, mu, log_sigma, train_edge_index.to('cuda'))\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a26b93",
      "metadata": {
        "id": "b3a26b93",
        "outputId": "2c195931-c53e-4e73-96c8-5a69ae1c96c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix A is on device: cuda:0\n",
            "A after adding self-loops: torch.Size([17859, 17859])\n",
            "Row sums: torch.Size([17859])\n",
            "D_inv_sqrt: torch.Size([17859, 17859])\n",
            "Normalized A: torch.Size([17859, 17859])\n",
            "Final normalized A: torch.Size([17859, 17859])\n"
          ]
        }
      ],
      "source": [
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix)\n",
        "A_tilde_train = A_tilde_train.to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fb777c",
      "metadata": {
        "id": "d3fb777c"
      },
      "outputs": [],
      "source": [
        "D = torch.diag(A_tilde_train.sum(dim=1).clamp(min=1).pow(-0.5))\n",
        "A_tilde_train = D @ A_tilde_train @ D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa3b6eb",
      "metadata": {
        "id": "aaa3b6eb"
      },
      "outputs": [],
      "source": [
        "A_tilde_train = A_tilde_train / A_tilde_train.sum(dim=1, keepdim=True).clamp(min=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83314192",
      "metadata": {
        "id": "83314192",
        "outputId": "2d9d689e-b4df-4a3d-87e0-72e182c7bdb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is A_tilde_train symmetric? True\n"
          ]
        }
      ],
      "source": [
        "is_symmetric = torch.allclose(train_adj_matrix, train_adj_matrix.T, atol=1e-6)\n",
        "print(\"Is A_tilde_train symmetric?\", is_symmetric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26421a9f",
      "metadata": {
        "id": "26421a9f",
        "outputId": "657333dd-2d8f-4c19-a491-1ff24f2d67d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is A_tilde_train symmetric? True\n"
          ]
        }
      ],
      "source": [
        "is_symmetric = torch.allclose(A_tilde_train, A_tilde_train.T, atol=1e-6)\n",
        "print(\"Is A_tilde_train symmetric?\", is_symmetric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d88a5c0",
      "metadata": {
        "id": "7d88a5c0",
        "outputId": "80b0fce5-74d3-4497-9a85-2926be8e6403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in train_adj_matrix[0]:\n",
        "    if i!=0:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130361bf",
      "metadata": {
        "id": "130361bf",
        "outputId": "da855555-2cbd-4f25-8de0-c46923c1cf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5000, device='cuda:0')\n",
            "tensor(0.0928, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for i in A_tilde_train[0]:\n",
        "    if i!=0:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "33a102ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "33a102ad",
        "outputId": "d76fc86f-5fc1-4fed-df91-8f1777c22e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: encoder.gcn1.weight | Weights: tensor([[ 0.2844, -1.2023,  0.0181,  ..., -0.3716,  0.4400, -2.0281],\n",
            "        [ 1.0278, -0.5476,  0.7557,  ...,  0.0956, -2.2373,  1.5964],\n",
            "        [ 1.0956,  1.1783,  0.8374,  ..., -0.7773,  1.4663,  0.3260],\n",
            "        ...,\n",
            "        [-1.5276, -0.2777,  0.4698,  ..., -1.6284,  1.6496,  0.4437],\n",
            "        [-2.3021, -0.9397,  0.8102,  ..., -0.7855, -1.8552, -1.1287],\n",
            "        [ 0.1980, -1.0253, -0.1974,  ...,  0.5522, -0.6829,  1.1012]],\n",
            "       device='cuda:0')\n",
            "Layer: encoder.gcn2_mu.weight | Weights: tensor([[-2.0520e-01,  1.9662e+00, -1.6177e+00, -1.2190e+00, -8.4244e-01,\n",
            "          5.6901e-01, -4.4265e-01, -8.6830e-01, -5.1377e-01,  2.6267e-01,\n",
            "          6.6546e-01, -1.6125e-01,  2.3547e+00, -1.0704e+00, -2.1678e+00,\n",
            "          4.7659e-01],\n",
            "        [ 1.6484e+00, -2.7656e-01, -1.7024e+00,  1.9620e-01,  6.7228e-01,\n",
            "          3.0308e-01,  4.6277e-01, -5.2939e-01,  5.0141e-01, -7.3981e-01,\n",
            "          5.4150e-01,  1.7330e-01,  1.3890e+00, -5.1541e-01,  1.7745e+00,\n",
            "          5.7773e-01],\n",
            "        [ 1.3168e+00,  7.8708e-02,  4.5959e-01, -1.0268e+00, -4.3306e-01,\n",
            "         -1.0508e+00,  1.1720e+00,  7.6949e-01,  9.5826e-01, -4.1392e-01,\n",
            "          2.7320e-01, -1.0906e+00, -2.1835e+00, -1.1551e-01, -5.9398e-01,\n",
            "          1.0247e-01],\n",
            "        [ 1.7834e-01,  4.7022e-01, -1.0566e+00,  2.1955e-01, -1.4001e+00,\n",
            "         -2.1211e-01, -1.2235e+00,  2.2615e-01, -5.5281e-01, -8.0760e-01,\n",
            "         -1.0814e+00, -5.4670e-01, -7.0431e-01,  2.3783e+00,  2.3357e+00,\n",
            "         -1.6741e+00],\n",
            "        [ 1.1235e+00, -3.1837e-01,  5.3031e-01,  1.3923e+00, -1.0688e+00,\n",
            "         -6.3562e-01, -2.3852e-01,  5.2435e-01, -1.2586e+00, -7.9627e-01,\n",
            "          1.7504e+00, -8.9033e-01, -1.8605e+00, -6.4451e-01,  4.6007e-01,\n",
            "         -4.2275e-01],\n",
            "        [-6.9552e-01, -1.0675e+00, -4.2611e-01, -7.2446e-01,  8.5018e-01,\n",
            "          4.5285e-01, -8.5905e-01, -1.4355e+00,  7.3954e-01, -3.2322e-01,\n",
            "         -2.9380e-01, -1.4693e+00, -6.3210e-01, -8.8264e-01, -2.1009e+00,\n",
            "         -6.9504e-01],\n",
            "        [ 2.5612e-01,  8.1533e-01, -1.2452e+00, -3.7306e-01,  2.4363e-01,\n",
            "          8.5416e-01, -7.1342e-01,  9.7030e-01,  1.7984e+00, -7.2146e-01,\n",
            "         -2.9556e-01,  1.0729e+00, -4.6043e-01, -6.1836e-01, -3.6233e-01,\n",
            "          1.4815e+00],\n",
            "        [-1.4680e-01, -2.6899e-01, -4.0835e-01,  9.9583e-01, -4.1570e-02,\n",
            "         -8.4278e-01, -8.1661e-01, -4.6319e-01, -1.1337e+00,  1.6579e-01,\n",
            "          1.6699e+00,  1.0450e+00, -1.7151e+00,  6.0993e-02, -4.7407e-01,\n",
            "          1.9257e-01],\n",
            "        [-1.1164e+00, -9.5514e-01, -4.6209e-01,  7.1067e-01, -4.6389e-01,\n",
            "         -2.8331e-01,  5.7031e-01,  4.1629e-01,  5.8270e-01,  1.8461e-01,\n",
            "          7.8281e-02,  6.6594e-01, -3.2422e-01, -1.3520e+00,  1.7201e+00,\n",
            "         -7.5127e-02],\n",
            "        [ 1.8769e+00, -1.6694e+00,  1.7458e-01, -1.5748e+00, -7.1060e-01,\n",
            "          1.1430e+00, -8.8332e-01,  6.6824e-01,  8.8873e-01,  6.6046e-01,\n",
            "          3.9558e-01, -1.7533e-01,  1.0422e-01, -1.4997e-01, -2.4668e-01,\n",
            "          5.0722e-01],\n",
            "        [ 8.5041e-01,  2.8004e-01,  9.5630e-01,  1.2759e+00,  1.4191e+00,\n",
            "          1.8718e-02, -9.6227e-01, -1.0770e+00, -7.6545e-01,  2.2452e-01,\n",
            "         -2.8602e-01,  1.6061e+00,  1.9460e-01,  2.5091e+00,  1.2251e+00,\n",
            "         -4.3581e-01],\n",
            "        [ 3.5098e-01,  4.5806e-01, -5.6069e-01,  8.0990e-01,  8.6844e-01,\n",
            "          8.7670e-02, -3.8636e-01,  9.8742e-01,  9.3991e-01, -1.2397e+00,\n",
            "         -4.3521e-01,  2.3616e-01, -1.4599e+00,  1.1105e+00,  1.0116e+00,\n",
            "          7.1415e-01],\n",
            "        [-8.6346e-01,  1.4826e+00, -1.7065e+00, -7.4600e-01,  9.7600e-01,\n",
            "         -6.2401e-02,  1.6006e-01,  1.2014e+00,  3.8794e-01, -4.9711e-01,\n",
            "         -8.4511e-01, -1.8204e+00, -1.8022e-01,  1.5874e-01, -9.7064e-02,\n",
            "          1.1091e+00],\n",
            "        [-1.2281e+00, -1.5139e-01,  2.1300e+00, -1.1560e+00,  1.0588e+00,\n",
            "         -1.4551e+00,  2.6475e-01,  1.7596e+00, -2.5299e+00,  3.9000e-01,\n",
            "          8.5222e-01, -6.9836e-01,  1.1640e-01, -3.0558e-01,  2.1531e-01,\n",
            "         -7.6737e-01],\n",
            "        [ 1.0468e+00, -6.5931e-01,  4.3175e-01, -7.1025e-01, -1.0749e+00,\n",
            "          3.5654e-02, -3.0257e-01,  2.0948e-01, -1.6821e+00, -1.1304e+00,\n",
            "          9.9713e-01, -1.2446e-02, -2.4205e-01,  5.7876e-01,  1.7135e+00,\n",
            "         -8.1247e-01],\n",
            "        [-1.3825e+00, -6.9115e-01,  9.6310e-03, -1.4110e+00, -4.3124e-01,\n",
            "         -1.5420e+00,  1.3014e+00, -3.6404e-01, -1.5612e+00,  2.5725e-01,\n",
            "         -5.9881e-01, -2.0420e+00, -2.0953e+00,  8.0478e-01, -5.4987e-01,\n",
            "         -1.0015e+00],\n",
            "        [-3.3992e-01,  1.4245e+00, -4.7839e-02, -3.7853e-01,  2.5045e-01,\n",
            "          6.4458e-01, -1.5630e+00,  4.2988e-01,  9.9131e-01, -1.1877e-01,\n",
            "         -1.9414e-01,  1.5584e+00,  1.5841e-01, -7.7325e-02,  6.3201e-01,\n",
            "          1.0356e+00],\n",
            "        [-7.4439e-01,  4.4488e-01, -4.1791e-01,  7.0811e-01, -6.0024e-01,\n",
            "          4.6145e-01, -1.3180e+00,  6.4020e-01, -2.6828e-01, -4.3741e-01,\n",
            "          6.3356e-01, -7.7723e-01, -9.3578e-02,  1.9052e-01, -7.3751e-01,\n",
            "          2.5488e-03],\n",
            "        [-9.3686e-02, -5.2207e-01,  1.0924e+00,  9.0088e-01,  1.0149e-01,\n",
            "         -3.0664e-02,  1.9448e+00, -3.5095e-01,  1.0619e+00,  6.6958e-02,\n",
            "         -6.8930e-01, -8.1039e-01,  8.4283e-02, -9.6948e-01, -5.7448e-01,\n",
            "          1.7312e-01],\n",
            "        [-8.7960e-01,  3.7778e-01, -5.7590e-01, -3.3376e-01,  1.8324e-01,\n",
            "          1.0986e+00, -1.0576e+00, -1.4848e+00,  9.9100e-01, -1.0174e+00,\n",
            "          3.0316e+00,  5.9445e-01, -2.2350e-02, -5.1808e-01,  9.9997e-01,\n",
            "         -1.0139e+00],\n",
            "        [ 5.5996e-01,  4.2843e-01, -4.7390e-01, -1.1665e+00, -8.7929e-01,\n",
            "          2.3113e+00,  5.4258e-01,  1.1506e-01, -1.3343e+00, -1.7819e-01,\n",
            "          8.0665e-01,  2.2906e+00,  9.3608e-01,  4.0863e-02, -3.7737e-01,\n",
            "         -4.5178e-01],\n",
            "        [ 1.6479e-01, -1.5204e+00,  1.8736e+00,  1.2706e+00,  4.8373e-02,\n",
            "         -3.9366e-01, -1.2570e+00,  6.7608e-01,  6.6082e-01,  6.6845e-01,\n",
            "          8.9796e-01,  1.3327e+00,  3.5767e-01,  1.8481e+00,  1.2346e+00,\n",
            "          1.0970e+00],\n",
            "        [ 7.0250e-01,  1.6513e+00,  6.1878e-01, -8.1983e-01,  5.4833e-01,\n",
            "         -8.1506e-01, -1.7411e+00,  1.2521e+00, -1.3357e+00, -1.0271e+00,\n",
            "          7.9406e-01, -8.2744e-01, -1.1065e+00,  1.2832e+00,  1.8545e+00,\n",
            "          7.6478e-01],\n",
            "        [ 3.8349e-01, -1.5812e-01, -2.0441e-01,  1.1352e+00, -1.8473e+00,\n",
            "          1.9538e+00,  1.3301e-02, -1.1548e+00,  1.4304e+00,  9.7202e-02,\n",
            "          2.0808e+00, -7.0716e-01,  1.6415e+00,  5.3284e-01, -4.5850e-01,\n",
            "         -6.1281e-01],\n",
            "        [ 1.0371e+00, -7.1311e-01, -4.8786e-01,  1.2960e+00,  8.5514e-01,\n",
            "         -2.0905e-01,  1.8276e+00, -1.2636e+00,  7.8060e-01, -2.1480e+00,\n",
            "         -8.9286e-01, -1.9184e+00, -4.4347e-01, -5.6472e-01, -6.2979e-01,\n",
            "          1.8325e-02],\n",
            "        [ 2.8075e-01,  2.3960e-02, -2.8000e+00, -3.4449e-01, -3.4260e-01,\n",
            "         -7.7714e-01, -8.7428e-01,  1.0400e+00, -2.1011e-01,  5.7457e-01,\n",
            "         -2.0796e+00, -1.9867e-01,  2.6547e-01, -4.5728e-01, -1.2588e+00,\n",
            "          9.9065e-01],\n",
            "        [ 1.3657e+00, -2.3883e-02, -3.6970e-01, -1.2769e+00, -2.2256e+00,\n",
            "         -8.7700e-01,  1.4590e+00, -1.2134e+00,  5.1757e-01, -2.4648e-01,\n",
            "          1.4940e+00, -1.0386e+00, -2.9707e-01, -1.1209e+00,  6.8237e-01,\n",
            "         -9.7462e-01],\n",
            "        [-1.1881e+00, -6.1461e-01,  1.6858e-01, -1.9316e+00,  2.2921e-01,\n",
            "          2.0413e-01, -2.9269e+00, -1.8737e+00,  3.9452e-01, -4.6179e-01,\n",
            "          9.3517e-01,  3.5057e-01,  3.7892e-01, -5.4529e-01, -5.5250e-01,\n",
            "          7.8232e-01],\n",
            "        [-1.8956e+00, -1.3374e+00,  7.4157e-02,  4.6744e-01, -1.1716e+00,\n",
            "         -1.4837e+00,  4.3954e-01,  1.4163e-01, -1.3781e+00,  1.6029e+00,\n",
            "          2.2627e+00, -2.1809e-01,  5.9853e-01,  5.7157e-01, -5.6806e-01,\n",
            "         -9.7642e-02],\n",
            "        [ 3.5183e-01,  2.4689e-01,  3.9397e-01, -1.5296e+00,  6.3844e-01,\n",
            "         -1.6037e+00,  9.8054e-01, -2.3590e+00, -4.6694e-01,  2.6329e-01,\n",
            "          4.0580e-01,  4.5794e-01,  1.2449e+00,  7.2208e-01, -1.3627e-01,\n",
            "         -2.3996e-01],\n",
            "        [-1.3629e+00,  1.9496e+00,  3.2941e-03, -1.8380e-02, -1.0538e+00,\n",
            "          5.6970e-01,  1.3406e+00,  2.9663e-01,  1.1654e+00,  1.5301e+00,\n",
            "          5.9087e-01, -9.4054e-01,  2.4778e-01,  8.4344e-01,  3.8588e-01,\n",
            "         -2.7851e-01],\n",
            "        [ 1.2459e+00, -6.3048e-01, -2.8180e+00, -2.1054e-02,  1.6594e+00,\n",
            "         -5.7383e-01, -6.8482e-01,  4.0682e-01,  4.2623e-01,  5.8737e-02,\n",
            "         -1.6172e+00,  2.5920e-01,  1.4551e+00, -2.6154e+00, -1.1348e+00,\n",
            "         -7.4230e-01]], device='cuda:0')\n",
            "Layer: encoder.gcn2_logsigma.weight | Weights: tensor([[-9.2141e-01, -1.9540e+00, -2.9581e-01,  2.7120e+00, -4.6647e-01,\n",
            "         -5.8937e-02,  1.9018e+00,  1.0515e+00,  1.7844e-01, -4.0195e-02,\n",
            "          3.9105e-01,  2.5392e-01, -5.8483e-01,  2.0586e-01, -1.2972e+00,\n",
            "         -1.4239e+00],\n",
            "        [-5.7493e-02, -2.6453e+00,  5.6886e-01,  7.6233e-02,  1.0370e+00,\n",
            "         -3.0334e-01, -1.8417e-01,  5.7459e-02, -9.9967e-01,  2.8336e-01,\n",
            "         -9.5166e-01, -7.6704e-01,  4.7758e-01,  7.0457e-01, -4.0580e-02,\n",
            "          2.1557e+00],\n",
            "        [-6.0909e-01, -9.8759e-02,  7.6298e-01, -5.7958e-02, -4.7684e-02,\n",
            "          2.0719e-01, -6.4655e-01, -9.1690e-02,  9.2065e-01, -8.5958e-01,\n",
            "          4.5421e-01, -2.3159e-01,  2.7867e-01, -1.9463e+00,  9.0471e-01,\n",
            "         -1.6808e+00],\n",
            "        [ 5.8735e-01,  6.0160e-01, -7.2889e-02,  1.3756e+00, -5.4208e-01,\n",
            "          1.6377e+00,  3.2020e-01,  2.9627e+00, -9.7327e-01,  3.9633e-01,\n",
            "          6.8959e-01, -9.1905e-01, -2.0705e-01, -5.8242e-01,  1.7915e+00,\n",
            "          5.3007e-01],\n",
            "        [-1.6829e+00,  1.6896e+00, -1.3156e+00, -9.1006e-01,  5.8716e-01,\n",
            "         -3.6387e-01, -8.3020e-01, -1.0490e+00,  5.6900e-01,  1.4802e+00,\n",
            "          5.7951e-01, -8.3828e-02, -2.4579e-01, -1.4995e+00,  1.2490e+00,\n",
            "          7.4609e-01],\n",
            "        [-3.5733e-02,  5.4228e-01,  6.7533e-01, -1.2321e+00, -7.0373e-01,\n",
            "         -8.6215e-01,  7.2381e-01,  4.6624e-01,  1.0920e+00, -1.2397e+00,\n",
            "          3.0136e-01,  8.5522e-01,  8.6100e-01, -8.8637e-01, -6.4115e-01,\n",
            "         -2.1095e-01],\n",
            "        [ 5.1082e-01,  6.9722e-01, -1.0963e+00, -1.6019e+00, -7.1145e-01,\n",
            "          2.8156e-02,  1.3021e+00, -1.1007e-01,  1.2300e-01, -2.0175e-01,\n",
            "          5.3981e-01,  5.6548e-01, -1.7993e+00, -6.1696e-01,  2.1237e+00,\n",
            "          1.1295e+00],\n",
            "        [-1.3249e+00,  1.1998e+00,  1.1028e+00, -8.0277e-02,  1.6627e-01,\n",
            "         -2.4595e+00,  7.7069e-01, -1.6422e+00,  2.6970e+00, -1.9580e-01,\n",
            "         -7.0880e-01,  1.1948e+00, -9.4100e-01, -1.8134e+00, -1.0603e+00,\n",
            "          9.4195e-01],\n",
            "        [-2.3437e-01, -1.8491e-01,  9.5231e-01,  9.4576e-01, -1.0254e-01,\n",
            "          5.8814e-01,  7.4864e-01,  9.2050e-01, -6.5948e-01, -1.0622e+00,\n",
            "          9.8950e-01,  8.4358e-01, -5.8907e-01,  5.1157e-01,  9.7336e-01,\n",
            "          5.6005e-01],\n",
            "        [ 7.7382e-01,  1.5622e+00, -6.5297e-01,  1.4507e+00,  6.3163e-01,\n",
            "          2.6563e-01, -8.3034e-01, -9.4703e-01, -7.0485e-01, -1.4153e+00,\n",
            "         -4.9484e-02,  5.5482e-02,  6.1699e-01,  2.8652e-01,  8.6609e-01,\n",
            "         -1.1374e+00],\n",
            "        [-1.4804e-01, -5.1079e-01, -2.8026e-01,  3.0081e-01, -4.2249e-01,\n",
            "          1.1203e+00,  1.2076e-01,  1.0048e+00,  8.0775e-01,  1.7560e+00,\n",
            "          2.9899e-02, -8.8744e-01,  2.2481e-01,  3.0053e+00, -2.3437e-01,\n",
            "          1.1318e+00],\n",
            "        [-3.3784e-01,  9.4016e-01, -1.9573e+00, -7.2869e-01, -1.3037e+00,\n",
            "          3.6639e-01,  1.6226e-01,  2.7376e-01, -3.4487e-01, -6.2036e-01,\n",
            "          3.6050e-01, -3.2673e-01, -3.7293e-01,  1.8768e+00, -8.5627e-01,\n",
            "          1.6711e+00],\n",
            "        [-7.4699e-02,  3.0664e-01,  1.2402e+00,  1.7136e-01, -3.1592e-01,\n",
            "         -2.5502e+00, -2.0653e-01,  3.5198e-01, -3.5411e-01, -3.3746e-01,\n",
            "          8.9701e-01, -4.8860e-01,  1.4076e+00, -4.1018e-01, -4.4026e-01,\n",
            "          1.3200e+00],\n",
            "        [ 2.6606e-01, -5.8312e-01,  1.2007e+00,  2.9280e-01,  6.3769e-01,\n",
            "         -1.3723e-01, -2.3235e+00, -1.2155e+00, -5.4981e-01, -1.6298e-01,\n",
            "         -7.0574e-01, -7.7825e-01, -6.6994e-01, -5.3603e-02, -7.7416e-01,\n",
            "         -7.7641e-01],\n",
            "        [-5.1880e-01,  1.5373e+00,  6.9986e-01,  4.5855e-02, -1.0287e+00,\n",
            "          5.5180e-02,  7.4860e-01,  1.5505e+00, -7.0154e-01,  1.3567e+00,\n",
            "          9.0599e-01, -4.1205e-01, -4.2015e-01, -1.4114e+00,  1.1635e-01,\n",
            "         -2.3906e-01],\n",
            "        [ 8.7134e-01,  9.3870e-01,  1.6861e+00,  9.7150e-01,  8.3444e-01,\n",
            "         -2.6049e-01,  1.1861e-01,  1.6702e+00, -1.0917e+00, -4.7454e-01,\n",
            "          8.5629e-01, -1.5184e-01,  3.2245e-01, -6.9515e-01,  1.5071e-01,\n",
            "          1.6261e+00],\n",
            "        [ 1.1567e-01,  3.3993e-01, -9.2595e-01, -1.2946e+00,  4.0131e-01,\n",
            "         -8.9953e-01,  1.4101e+00,  2.4130e-02,  4.9276e-01,  5.9595e-01,\n",
            "         -6.0962e-01, -2.0059e-01,  3.2423e-01,  1.3130e+00,  7.7560e-01,\n",
            "          5.4224e-01],\n",
            "        [ 4.9709e-01,  4.8738e-01,  1.0773e-01, -8.2796e-01, -6.0323e-01,\n",
            "          3.1927e-02,  3.6263e-01, -8.9965e-02, -5.5229e-01,  4.5224e-01,\n",
            "         -9.2796e-01,  6.7697e-01,  1.5828e+00,  4.6869e-02, -3.4441e-01,\n",
            "          1.3388e+00],\n",
            "        [ 1.4944e-02,  4.8994e-01, -1.1309e+00, -6.4887e-01, -3.6036e-01,\n",
            "          4.7937e-01, -3.8787e-01, -1.2120e+00, -1.2187e+00,  2.9599e-01,\n",
            "         -4.2849e-01, -1.1230e+00, -2.9455e-02, -7.2889e-01, -2.9656e-01,\n",
            "         -1.4011e+00],\n",
            "        [ 4.2422e-01,  1.5747e+00,  1.3828e+00, -2.4751e-01,  1.2071e+00,\n",
            "         -2.0032e+00,  1.8950e+00, -1.0046e+00,  7.9843e-01, -1.1747e+00,\n",
            "          9.9161e-01,  1.0510e-01,  1.3967e-01,  7.7543e-01,  1.7133e+00,\n",
            "          5.0768e-01],\n",
            "        [ 1.0604e+00, -1.2559e+00, -2.3835e+00, -1.1449e-01,  3.2941e-01,\n",
            "          3.0442e-01, -1.2291e+00, -1.5910e+00,  3.1858e-01, -8.9526e-01,\n",
            "          2.7717e+00,  1.4643e+00,  5.5738e-01,  1.2079e-02, -8.0204e-02,\n",
            "          6.9688e-01],\n",
            "        [ 4.9107e-01, -3.5148e-02,  4.7043e-01, -6.8787e-01, -1.3322e+00,\n",
            "         -6.9959e-01, -1.2314e+00, -6.0506e-01,  4.5748e-01, -3.5686e-01,\n",
            "          1.2218e-01,  7.8134e-01,  1.3320e-01,  2.3436e-02,  1.1046e+00,\n",
            "         -4.0321e-01],\n",
            "        [ 1.1729e-01,  4.1610e-01, -7.9622e-01,  1.0908e-02,  2.9102e+00,\n",
            "          1.1471e+00,  2.3714e+00,  9.6535e-01,  2.0807e-01,  3.1004e-01,\n",
            "         -1.8728e+00, -4.9725e-01, -5.8545e-01,  1.7670e-01,  1.6335e-01,\n",
            "          1.9642e+00],\n",
            "        [ 6.7816e-01, -1.3395e+00,  1.3415e-01,  1.1892e+00,  2.9776e-01,\n",
            "          1.5861e+00, -2.2631e+00, -2.0201e-01,  3.3639e-01,  3.7793e-01,\n",
            "         -7.4924e-02,  3.8608e-01,  1.3444e+00, -4.6636e-01,  7.7037e-01,\n",
            "          8.3592e-01],\n",
            "        [-1.0788e+00,  1.4075e-01,  1.8679e+00,  6.1374e-01,  3.9166e-01,\n",
            "          2.6775e-01,  1.1100e+00,  1.6885e+00,  5.7325e-02,  4.8946e-01,\n",
            "          8.8939e-02, -5.3734e-01,  9.1849e-01,  1.0333e-01,  4.4895e-01,\n",
            "         -8.7479e-02],\n",
            "        [-8.2428e-02, -8.1585e-01,  1.0295e-01,  5.6134e-01, -1.6589e-03,\n",
            "         -3.3889e-02,  5.0329e-01,  1.1939e+00, -2.4173e-01,  7.8728e-01,\n",
            "         -4.8220e-01,  1.5867e+00,  3.2619e-01, -8.1880e-02, -3.7315e-01,\n",
            "          2.5845e-02],\n",
            "        [-3.9694e-01, -4.2626e-01, -7.3189e-01,  3.1707e-01, -5.9128e-01,\n",
            "         -1.4515e-01,  1.6486e+00,  1.1896e+00, -1.1535e+00,  1.9052e+00,\n",
            "         -1.8238e+00, -1.2105e+00,  1.0081e-01, -1.4178e+00,  1.2747e-01,\n",
            "         -1.9626e+00],\n",
            "        [-6.0757e-01, -1.1180e-02,  2.1156e+00, -1.4394e+00,  1.5798e-01,\n",
            "         -9.0143e-01, -5.6334e-01,  1.2812e+00,  1.2841e+00,  6.1005e-01,\n",
            "         -5.1258e-02,  4.9767e-02, -1.0057e+00,  1.8015e-01, -4.1732e-01,\n",
            "         -1.5201e+00],\n",
            "        [ 5.0871e-01, -1.3445e+00, -5.8237e-01,  2.1791e-01, -6.0099e-01,\n",
            "          1.6722e+00, -1.3433e+00, -1.3261e+00, -7.1367e-01,  1.0347e+00,\n",
            "         -2.6243e+00,  2.4825e-01, -1.0446e+00,  7.5850e-01,  3.9050e-01,\n",
            "          1.4829e+00],\n",
            "        [ 8.8563e-01,  1.6582e-01, -5.8295e-01,  3.2993e-01,  1.2484e+00,\n",
            "         -1.5010e+00, -7.1359e-01,  1.2932e+00,  1.6052e+00, -4.3751e-01,\n",
            "          1.8410e+00,  1.0150e+00, -1.6205e-02, -7.5778e-01,  3.9033e-01,\n",
            "          5.8858e-02],\n",
            "        [ 5.6595e-01, -6.4867e-01, -8.4955e-02,  3.7025e-01, -8.3534e-02,\n",
            "          1.5637e+00,  8.7363e-01, -5.0208e-01, -9.4935e-01,  2.2304e-01,\n",
            "         -2.3898e-01, -1.4433e+00, -1.8020e-02, -1.5117e+00, -7.2437e-01,\n",
            "          1.2560e+00],\n",
            "        [-6.2648e-01,  4.3623e-02,  8.0970e-02,  1.0145e+00,  3.8739e-01,\n",
            "          4.7584e-01, -5.4130e-01, -4.7828e-01, -1.3007e+00, -1.0037e+00,\n",
            "         -6.9693e-01,  1.6714e+00,  6.8868e-01,  1.7619e-01, -1.2210e+00,\n",
            "         -4.4631e-01]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"Layer: {name} | Weights: {param.data}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47108e68",
      "metadata": {
        "id": "47108e68"
      },
      "outputs": [],
      "source": [
        "Layer: decoder.weight | Weights: tensor([ 0.7694,  0.7375,  0.7400,  0.8426,  0.6726,  0.5184,  0.8114, -0.0369,\n",
        "         0.8284,  0.7812,  0.6179,  0.5305,  0.7229,  0.0629,  0.1734,  0.5006]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74ebffb",
      "metadata": {
        "id": "b74ebffb"
      },
      "outputs": [],
      "source": [
        "Layer: decoder.weight | Weights: tensor([0.2511, 0.4997, 0.5713, 0.3977, 0.4057, 0.6872, 0.3339, 0.1781, 0.3881,\n",
        "        0.8694, 0.3839, 0.3271, 0.4893, 0.7137, 0.7647, 0.5228],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6560bb73",
      "metadata": {
        "id": "6560bb73",
        "outputId": "99ccde99-86db-46aa-f186-983a994e4ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row sum min: 0.2660941779613495\n",
            "Row sum max: 21.876142501831055\n",
            "Row sum mean: 0.6087040901184082\n"
          ]
        }
      ],
      "source": [
        "row_sums=A_tilde_train.sum(dim=1)\n",
        "print(\"Row sum min:\", row_sums.min().item())\n",
        "print(\"Row sum max:\", row_sums.max().item())\n",
        "print(\"Row sum mean:\", row_sums.mean().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccba4220",
      "metadata": {
        "id": "ccba4220"
      },
      "outputs": [],
      "source": [
        "def split_edges_and_sample(A, num_samples=None, test_size=0.1, val_size=0.05, random_state=42):\n",
        "    \"\"\"\n",
        "    Efficiently splits edges and samples non-edges.\n",
        "\n",
        "    Parameters:\n",
        "    - A: scipy.sparse.coo_matrix (adjacency matrix)\n",
        "    - num_samples: Number of non-edges to sample (adjust based on graph size)\n",
        "    - test_size: Proportion of edges/non-edges for testing\n",
        "    - val_size: Proportion of edges/non-edges for validation\n",
        "    - random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - train_edge_index: Edge list for training\n",
        "    - val_edges, test_edges: Validation and test edge lists\n",
        "    - val_non_edges, test_non_edges: Validation and test non-edges\n",
        "    - train_graph: Sparse matrix representing the training graph\n",
        "    \"\"\"\n",
        "    A_coo = coo_matrix(A)\n",
        "    edges = np.vstack((A_coo.row, A_coo.col)).T  # Extract edges\n",
        "    num_nodes = A.shape[0]\n",
        "\n",
        "    # Normalize edge representation to avoid both (i, j) and (j, i)\n",
        "    edges = np.array([tuple(sorted((i, j))) for i, j in edges])\n",
        "    existing_edges = set(map(tuple, edges))\n",
        "\n",
        "    # Sample non-edges\n",
        "    if num_samples is None:\n",
        "        num_samples = int(len(edges) * 0.15)  # Sample 15% of edges as non-edges by default\n",
        "\n",
        "    np.random.seed(random_state)\n",
        "    non_edges = set()\n",
        "    while len(non_edges) < num_samples:\n",
        "        i = np.random.randint(0, num_nodes)\n",
        "        j = np.random.randint(0, num_nodes)\n",
        "        if i != j:\n",
        "            edge = tuple(sorted((i, j)))\n",
        "            if edge not in existing_edges:\n",
        "                non_edges.add(edge)\n",
        "\n",
        "    non_edges = np.array(list(non_edges))\n",
        "\n",
        "    # Split edges into train, validation, and test sets\n",
        "    train_edges, temp_edges = train_test_split(edges, test_size=(test_size + val_size), random_state=random_state)\n",
        "    val_edges, test_edges = train_test_split(temp_edges, test_size=(test_size / (test_size + val_size)), random_state=random_state)\n",
        "\n",
        "    # Split sampled non-edges into validation and test sets\n",
        "    val_non_edges, test_non_edges = train_test_split(non_edges, test_size=(test_size / (test_size + val_size)), random_state=random_state)\n",
        "\n",
        "    # Create a training graph (without val/test edges)\n",
        "    train_graph = coo_matrix(\n",
        "        (np.ones(len(train_edges)), (train_edges[:, 0], train_edges[:, 1])),\n",
        "        shape=A.shape\n",
        "    )\n",
        "    train_graph = train_graph + train_graph.T  # Ensure symmetry\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_edge_index = torch.tensor(train_edges.T, dtype=torch.long)\n",
        "    val_edges = torch.tensor(val_edges, dtype=torch.long)\n",
        "    test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
        "    val_non_edges = torch.tensor(val_non_edges, dtype=torch.long)\n",
        "    test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n",
        "\n",
        "    return train_edge_index, val_edges, test_edges, val_non_edges, test_non_edges, train_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_sparse -f https://pytorch-geometric.com/whl/cpu.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uY6kRQebYHc",
        "outputId": "2db57367-00e2-4230-a468-fb19af18138b"
      },
      "id": "8uY6kRQebYHc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/cpu.html\n",
            "Collecting torch_sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Building wheels for collected packages: torch_sparse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "0ed7204d",
      "metadata": {
        "id": "0ed7204d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "#import torch_sparse\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "# Assume edge_index, num_nodes, and remove_edges_and_sample_optimized are defined\n",
        "# Extract train graph adjacency matrix\n",
        "\n",
        "# Extract train graph adjacency matrix\n",
        "num_nodes = train_edge_index.max().item() + 1\n",
        "\n",
        "train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "# Convert to SciPy sparse matrix\n",
        "# Create the adjacency matrix from the edge list (train_edge_index)\n",
        "#train_adj_matrix = to_dense_adj(train_edge_index, max_num_nodes=num_nodes)[0]\n",
        "\n",
        "# Enforce symmetry (add the transpose to ensure both directions are captured)\n",
        "train_adj_matrix = train_adj_matrix + train_adj_matrix.T\n",
        "\n",
        "# Ensure that the diagonal entries are 1 (self-loops)\n",
        "train_adj_matrix.fill_diagonal_(1.0)\n",
        "train_adj_matrix = train_adj_matrix.clamp(max=1)\n",
        "#train_adj_matrix = to_scipy_sparse_matrix(train_edge_index, num_nodes=num_nodes)\n",
        "\n",
        "# Convert directly to a PyTorch sparse tensor\n",
        "#train_adj_matrix = torch.tensor(train_adj_matrix.toarray(), dtype=torch.float32)\n",
        "\n",
        "# Normalize adjacency for training graph\n",
        "A_tilde_train = normalize_adjacency_dense_gpu(train_adj_matrix.to(torch.float32))  # Normalize\n",
        "#D = torch.diag(train_adj_matrix.sum(dim=1).clamp(min=1).pow(-0.5))\n",
        "#A_tilde_train = D @ train_adj_matrix @ D\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "model = VGAE(input_dim, hidden_dim, latent_dim)\n",
        "\n",
        "model = model.to('cuda')  # Move model to GPU if available\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "88260e82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "88260e82",
        "outputId": "00e914eb-4c39-4ca6-9944-5a62b0d1296c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 71663824.0\n",
            "NaN detected in H!\n",
            "NaN detected in std!\n",
            "NaN detected in mu!\n",
            "NaN detected in log_sigma!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-775ea90161a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}, Loss: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# Training OLD\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    Z, A_reconstructed, mu, log_sigma = model(X.to('cuda'), A_tilde_train.to('cuda'))\n",
        "\n",
        "    # Clamp log_sigma to prevent extreme values\n",
        "    log_sigma = torch.clamp(log_sigma, min=-18, max=18)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function(train_adj_matrix.to('cuda'), A_reconstructed.to('cuda'), mu, log_sigma)\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c9ee4f7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ee4f7a",
        "outputId": "0fe66876-a7c5-4092-e792-8a76c707abd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-a034f13ef9ad>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
            "<ipython-input-33-a034f13ef9ad>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Convert the reconstructed adjacency matrix to CPU if necessary\n",
        "A_reconstructed = A_reconstructed.detach().cpu()\n",
        "\n",
        "# Ensure test edges and non-edges are tensors\n",
        "test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
        "test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n",
        "\n",
        "# Handle different decoder outputs\n",
        "if A_reconstructed.dim() == 2:\n",
        "    # If A_reconstructed is a full adjacency matrix\n",
        "    test_edge_scores = A_reconstructed[test_edges[:, 0], test_edges[:, 1]].numpy()\n",
        "    test_non_edge_scores = A_reconstructed[test_non_edges[:, 0], test_non_edges[:, 1]].numpy()\n",
        "else:\n",
        "    # If A_reconstructed is a 1D tensor (edge probabilities only)\n",
        "    test_edge_scores = A_reconstructed[:len(test_edges)].numpy()\n",
        "    test_non_edge_scores = A_reconstructed[len(test_edges):].numpy()\n",
        "\n",
        "# Combine scores and create labels\n",
        "scores = np.concatenate([test_edge_scores, test_non_edge_scores])\n",
        "labels = np.concatenate([np.ones(len(test_edge_scores)), np.zeros(len(test_non_edge_scores))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f569b3c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f569b3c5",
        "outputId": "5578b27d-bc83-4781-cbef-6778b00cd7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.5003852210158115\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Assuming y_true contains actual edge labels (1 for edges, 0 for non-edges)\n",
        "# and y_score contains the predicted scores for each pair of nodes\n",
        "roc_auc = roc_auc_score(labels, scores)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8aa7448d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aa7448d",
        "outputId": "05756b51-e672-493d-9872-9d2a030e791c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision (AP): 0.1197\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "ap_score = average_precision_score(labels, scores)\n",
        "print(f\"Average Precision (AP): {ap_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a037bc24",
      "metadata": {
        "id": "a037bc24"
      },
      "source": [
        "## GAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "cb174de9",
      "metadata": {
        "id": "cb174de9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    GAE\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_channels, out_channels))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
        "\n",
        "    def forward(self, X, A):\n",
        "\n",
        "        support = torch.matmul(X, self.weight)  # Apply linear transformation\n",
        "        output = torch.matmul(A, support)  # Aggregate neighbor information\n",
        "        return output + self.bias  # Add bias term\n",
        "\n",
        "class GAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(GAE, self).__init__()\n",
        "        # Encoder layers\n",
        "        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n",
        "        self.gcn2 = GCNLayer(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, X, A_tilde):\n",
        "\n",
        "        # Graph convolution layer 1\n",
        "        H = F.relu(self.gcn1(X, A_tilde))  # First GCN layer with ReLU activation\n",
        "\n",
        "        # Graph convolution layer 2\n",
        "        Z = self.gcn2(H, A_tilde)  # Second GCN layer for embeddings Z\n",
        "\n",
        "        # Normalize the embeddings (optional, based on your specific use case)\n",
        "        Z = F.normalize(Z, p=2, dim=1)  # Normalize each row of Z to have unit length\n",
        "\n",
        "        # Reconstruct the adjacency matrix\n",
        "        A_reconstructed = torch.sigmoid(torch.matmul(Z, Z.T))  # Reconstruct the adjacency matrix\n",
        "\n",
        "        return Z, A_reconstructed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "id": "40f66709",
      "metadata": {
        "id": "40f66709"
      },
      "outputs": [],
      "source": [
        "def loss_function(A, A_reconstructed):\n",
        "\n",
        "    A = A.view(-1)\n",
        "    A_reconstructed = A_reconstructed.view(-1)\n",
        "\n",
        "    return F.binary_cross_entropy(A_reconstructed, A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "id": "5eb6b9f7",
      "metadata": {
        "id": "5eb6b9f7"
      },
      "outputs": [],
      "source": [
        "train_adj_matrix = to_dense_adj_custom(train_edge_index, max_num_nodes=num_nodes)[0]  # Convert to dense adjacency matrix\n",
        "train_adj_matrix = train_adj_matrix.to(torch.float32)  # Ensure float type for computations\n",
        "\n",
        "# Node features\n",
        "if data.x is not None:\n",
        "    X = data.x  # Use provided node features\n",
        "else:\n",
        "    X = torch.eye(num_nodes)  # Use identity matrix if featureless\n",
        "\n",
        "\n",
        "A_tilde = normalize_adjacency_dense_gpu(train_adj_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "id": "89c333b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c333b1",
        "outputId": "1167c7af-18f7-4394-81ce-cb85b0805c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/200, Loss: 0.7204144597053528\n",
            "Epoch 20/200, Loss: 0.7118179202079773\n",
            "Epoch 30/200, Loss: 0.7078151702880859\n",
            "Epoch 40/200, Loss: 0.7055830955505371\n",
            "Epoch 50/200, Loss: 0.7051553130149841\n",
            "Epoch 60/200, Loss: 0.7044070363044739\n",
            "Epoch 70/200, Loss: 0.7040360569953918\n",
            "Epoch 80/200, Loss: 0.7036408185958862\n",
            "Epoch 90/200, Loss: 0.7033143043518066\n",
            "Epoch 100/200, Loss: 0.7030094265937805\n",
            "Epoch 110/200, Loss: 0.702742874622345\n",
            "Epoch 120/200, Loss: 0.7025085687637329\n",
            "Epoch 130/200, Loss: 0.7023085951805115\n",
            "Epoch 140/200, Loss: 0.7021378874778748\n",
            "Epoch 150/200, Loss: 0.7019903063774109\n",
            "Epoch 160/200, Loss: 0.7018605470657349\n",
            "Epoch 170/200, Loss: 0.7017422914505005\n",
            "Epoch 180/200, Loss: 0.7016328573226929\n",
            "Epoch 190/200, Loss: 0.7015302777290344\n",
            "Epoch 200/200, Loss: 0.7014331817626953\n"
          ]
        }
      ],
      "source": [
        "input_dim = X.shape[1]  # Number of features per node\n",
        "hidden_dim = 32  # Hidden layer size\n",
        "latent_dim = 16  # Latent space size (embedding dimension)\n",
        "num_epochs = 200\n",
        "learning_rate = 0.01\n",
        "device='cuda'\n",
        "\n",
        "\n",
        "model = GAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    Z, A_reconstructed = model(X.to(device), train_adj_matrix.to(device))\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function(train_adj_matrix.to(device), A_reconstructed)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "20ec5f4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ec5f4d",
        "outputId": "c99b44c8-e517-4f66-d6a5-1412b4ba3667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8122218861795278\n",
            "Average Precision (AP): 0.8354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-234-fc7ab8b836bb>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
            "<ipython-input-234-fc7ab8b836bb>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Convert the reconstructed adjacency matrix to CPU if necessary\n",
        "A_reconstructed = A_reconstructed.detach().cpu()\n",
        "\n",
        "test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
        "test_non_edges = torch.tensor(test_non_edges, dtype=torch.long)\n",
        "# Get the scores for test edges and test non-edges\n",
        "test_edge_scores = A_reconstructed[test_edges[:, 0], test_edges[:, 1]].numpy()\n",
        "test_non_edge_scores = A_reconstructed[test_non_edges[:, 0], test_non_edges[:, 1]].numpy()\n",
        "\n",
        "# Combine scores and create labels\n",
        "scores = np.concatenate([test_edge_scores, test_non_edge_scores])\n",
        "labels = np.concatenate([np.ones(len(test_edge_scores)), np.zeros(len(test_non_edge_scores))])\n",
        "\n",
        "# Assuming y_true contains actual edge labels (1 for edges, 0 for non-edges)\n",
        "# and y_score contains the predicted scores for each pair of nodes\n",
        "roc_auc = roc_auc_score(labels, scores)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n",
        "\n",
        "ap_score = average_precision_score(labels, scores)\n",
        "print(f\"Average Precision (AP): {ap_score:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f51d4edf",
        "89ff2f59",
        "a037bc24"
      ],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}